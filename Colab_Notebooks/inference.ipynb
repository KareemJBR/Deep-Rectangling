{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fix_convs.ipynb","provenance":[{"file_id":"1zhUCdaOg7MtU2oH2gSc51Cg4Zz2iRV_r","timestamp":1660385801479}],"collapsed_sections":[],"mount_file_id":"17jM1F10lendaW44e6Ge7XwMDVmzZDjRm","authorship_tag":"ABX9TyNFNW2HK9cf2GW/+zLr/9cc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install tf_slim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kIQ08A1rqRB","executionInfo":{"status":"ok","timestamp":1660385971713,"user_tz":-180,"elapsed":5620,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}},"outputId":"7d32ae4c-1ebb-45af-cb6c-31d9e8b174cd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tf_slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (1.2.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8ZMNybc6adph","executionInfo":{"status":"ok","timestamp":1660385971713,"user_tz":-180,"elapsed":5,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}}},"outputs":[],"source":["# training dataset path\n","TRAIN_FOLDER = '/content/drive/MyDrive/Colab Notebooks/DIR-D/training'\n","\n","# testing dataset path\n","TEST_FOLDER = '/content/drive/MyDrive/Colab Notebooks/DIR-D/testing'\n","\n","# GPU index\n","GPU = '0'\n","\n","# batch size for training\n","TRAIN_BATCH_SIZE = 1\n","\n","# batch size for testing\n","TEST_BATCH_SIZE = 1\n","\n","# num of iterations\n","ITERATIONS = 100000\n","\n","# checkpoints path\n","SNAPSHOT_DIR = \"/content/drive/MyDrive/Colab Notebooks/checkpoints\"\n","\n","# summary path\n","SUMMARY_DIR = \"/content/drive/MyDrive/Colab Notebooks/summary\"\n","\n","# define the mesh resolution\n","GRID_W = 8\n","GRID_H = 6"]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","#######################################################\n","# Auxiliary matrices used to solve DLT\n","Aux_M1 = np.array([\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 1, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 1, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 1, 0]], dtype=np.float64)\n","\n","Aux_M2 = np.array([\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 1, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 1, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 1, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 1]], dtype=np.float64)\n","\n","Aux_M3 = np.array([\n","    [0],\n","    [1],\n","    [0],\n","    [1],\n","    [0],\n","    [1],\n","    [0],\n","    [1]], dtype=np.float64)\n","\n","Aux_M4 = np.array([\n","    [-1, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, -1, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, -1, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, -1, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0]], dtype=np.float64)\n","\n","Aux_M5 = np.array([\n","    [0, -1, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, -1, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, -1, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, -1],\n","    [0, 0, 0, 0, 0, 0, 0, 0]], dtype=np.float64)\n","\n","Aux_M6 = np.array([\n","    [-1],\n","    [0],\n","    [-1],\n","    [0],\n","    [-1],\n","    [0],\n","    [-1],\n","    [0]], dtype=np.float64)\n","\n","Aux_M71 = np.array([\n","    [0, 1, 0, 0, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 1, 0, 0, 0, 0],\n","    [0, 0, 1, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 1, 0, 0],\n","    [0, 0, 0, 0, 1, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 1],\n","    [0, 0, 0, 0, 0, 0, 1, 0]], dtype=np.float64)\n","\n","Aux_M72 = np.array([\n","    [1, 0, 0, 0, 0, 0, 0, 0],\n","    [-1, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 1, 0, 0, 0, 0, 0],\n","    [0, 0, -1, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 1, 0, 0, 0],\n","    [0, 0, 0, 0, -1, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 1, 0],\n","    [0, 0, 0, 0, 0, 0, -1, 0]], dtype=np.float64)\n","\n","Aux_M8 = np.array([\n","    [0, 1, 0, 0, 0, 0, 0, 0],\n","    [0, -1, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 1, 0, 0, 0, 0],\n","    [0, 0, 0, -1, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 1, 0, 0],\n","    [0, 0, 0, 0, 0, -1, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 1],\n","    [0, 0, 0, 0, 0, 0, 0, -1]], dtype=np.float64)\n","\n","Aux_Mb = np.array([\n","    [0, -1, 0, 0, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, -1, 0, 0, 0, 0],\n","    [0, 0, 1, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, -1, 0, 0],\n","    [0, 0, 0, 0, 1, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, -1],\n","    [0, 0, 0, 0, 0, 0, 1, 0]], dtype=np.float64)\n","\n","\n","########################################################\n","\n","def solve_DLT(orig_pt4, pred_pt4):\n","    batch_size = tf.shape(input=orig_pt4)[0]\n","    orig_pt4 = tf.expand_dims(orig_pt4, [2])\n","    pred_pt4 = tf.expand_dims(pred_pt4, [2])\n","\n","    # Auxiliary tensors used to create Ax = b equation\n","    m1 = tf.constant(Aux_M1, tf.float32)\n","    m1_tensor = tf.expand_dims(m1, [0])\n","    m1_tile = tf.tile(m1_tensor, [batch_size, 1, 1])\n","\n","    m2 = tf.constant(Aux_M2, tf.float32)\n","    m2_tensor = tf.expand_dims(m2, [0])\n","    m2_tile = tf.tile(m2_tensor, [batch_size, 1, 1])\n","\n","    m3 = tf.constant(Aux_M3, tf.float32)\n","    m3_tensor = tf.expand_dims(m3, [0])\n","    m3_tile = tf.tile(m3_tensor, [batch_size, 1, 1])\n","\n","    m4 = tf.constant(Aux_M4, tf.float32)\n","    m4_tensor = tf.expand_dims(m4, [0])\n","    m4_tile = tf.tile(m4_tensor, [batch_size, 1, 1])\n","\n","    m5 = tf.constant(Aux_M5, tf.float32)\n","    m5_tensor = tf.expand_dims(m5, [0])\n","    m5_tile = tf.tile(m5_tensor, [batch_size, 1, 1])\n","\n","    m6 = tf.constant(Aux_M6, tf.float32)\n","    m6_tensor = tf.expand_dims(m6, [0])\n","    m6_tile = tf.tile(m6_tensor, [batch_size, 1, 1])\n","\n","    m71 = tf.constant(Aux_M71, tf.float32)\n","    m71_tensor = tf.expand_dims(m71, [0])\n","    m71_tile = tf.tile(m71_tensor, [batch_size, 1, 1])\n","\n","    m72 = tf.constant(Aux_M72, tf.float32)\n","    m72_tensor = tf.expand_dims(m72, [0])\n","    m72_tile = tf.tile(m72_tensor, [batch_size, 1, 1])\n","\n","    m8 = tf.constant(Aux_M8, tf.float32)\n","    m8_tensor = tf.expand_dims(m8, [0])\n","    m8_tile = tf.tile(m8_tensor, [batch_size, 1, 1])\n","\n","    mb = tf.constant(Aux_Mb, tf.float32)\n","    mb_tensor = tf.expand_dims(mb, [0])\n","    mb_tile = tf.tile(mb_tensor, [batch_size, 1, 1])\n","\n","    # Form the equations Ax = b to compute H\n","    # Form A matrix\n","    a1 = tf.matmul(m1_tile, orig_pt4)  # Column 1\n","    a2 = tf.matmul(m2_tile, orig_pt4)  # Column 2\n","    a3 = m3_tile  # Column 3\n","    a4 = tf.matmul(m4_tile, orig_pt4)  # Column 4\n","    a5 = tf.matmul(m5_tile, orig_pt4)  # Column 5\n","    a6 = m6_tile  # Column 6\n","    a7 = tf.matmul(m71_tile, pred_pt4) * tf.matmul(m72_tile, orig_pt4)  # Column 7\n","    a8 = tf.matmul(m71_tile, pred_pt4) * tf.matmul(m8_tile, orig_pt4)  # Column 8\n","\n","    # tmp = tf.reshape(a1, [-1, 8])  #batch_size * 8\n","    # A_mat: batch_size * 8 * 8          a1-A8相当�?*8中的每一�?\n","    a_mat = tf.transpose(a=tf.stack([tf.reshape(a1, [-1, 8]), tf.reshape(a2, [-1, 8]),\n","                                   tf.reshape(a3, [-1, 8]), tf.reshape(a4, [-1, 8]),\n","                                   tf.reshape(a5, [-1, 8]), tf.reshape(a6, [-1, 8]),\n","                                   tf.reshape(a7, [-1, 8]), tf.reshape(a8, [-1, 8])], axis=1),\n","                         perm=[0, 2, 1])  # BATCH_SIZE x 8 (A_i) x 8\n","    print('--Shape of A_mat:', a_mat.get_shape().as_list())\n","    # Form b matrix\n","    b_mat = tf.matmul(mb_tile, pred_pt4)\n","    print('--shape of b:', b_mat.get_shape().as_list())\n","\n","    # Solve the Ax = b\n","    h_8el = tf.linalg.solve(a_mat, b_mat)  # BATCH_SIZE x 8.\n","    print('--shape of H_8el', h_8el)\n","\n","    # Add ones to the last cols to reconstruct H for computing reprojection error\n","    h_ones = tf.ones([batch_size, 1, 1])\n","    h_9el = tf.concat([h_8el, h_ones], 1)\n","    h_flat = tf.reshape(h_9el, [-1, 9])\n","    # H_mat = tf.reshape(h_flat ,[-1 ,3 ,3])   # BATCH_SIZE x 3 x 3\n","    return h_flat"],"metadata":{"id":"EpbN5g05p7ux","executionInfo":{"status":"ok","timestamp":1660385975770,"user_tz":-180,"elapsed":4062,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","import tensorflow as tf\n","from keras.layers import UpSampling2D\n","\n","grid_w = GRID_W\n","grid_h = GRID_H\n","\n","\n","def transformer(_u, mask, theta, name='SpatialTransformer'):\n","    def _repeat(x, n_repeats):\n","        with tf.compat.v1.variable_scope('_repeat'):\n","            rep = tf.transpose(\n","                a=tf.expand_dims(tf.ones(shape=tf.stack([n_repeats, ])), 1), perm=[1, 0])\n","            rep = tf.cast(rep, 'int32')\n","            x = tf.matmul(tf.reshape(x, (-1, 1)), rep)\n","            return tf.reshape(x, [-1])\n","\n","    def _interpolate(im, x, y, out_size):\n","        with tf.compat.v1.variable_scope('_interpolate'):\n","            # constants\n","            num_batch = tf.shape(input=im)[0]\n","            height = tf.shape(input=im)[1]\n","            width = tf.shape(input=im)[2]\n","            channels = tf.shape(input=im)[3]\n","\n","            x = tf.cast(x, 'float32')\n","            y = tf.cast(y, 'float32')\n","\n","            out_height = out_size[0]\n","            out_width = out_size[1]\n","            zero = tf.zeros([], dtype='int32')\n","            max_y = tf.cast(tf.shape(input=im)[1] - 1, 'int32')\n","            max_x = tf.cast(tf.shape(input=im)[2] - 1, 'int32')\n","\n","            # scale indices from [-1, 1] to [0, width/height]\n","            # x = (x + 1.0)*(width_f) / 2.0\n","            # y = (y + 1.0)*(height_f) / 2.0\n","\n","            # do sampling\n","            x0 = tf.cast(tf.floor(x), 'int32')\n","            x1 = x0 + 1\n","            y0 = tf.cast(tf.floor(y), 'int32')\n","            y1 = y0 + 1\n","\n","            x0 = tf.clip_by_value(x0, zero, max_x)\n","            x1 = tf.clip_by_value(x1, zero, max_x)\n","            y0 = tf.clip_by_value(y0, zero, max_y)\n","            y1 = tf.clip_by_value(y1, zero, max_y)\n","            dim2 = width\n","            dim1 = width * height\n","            base = _repeat(tf.range(num_batch) * dim1, out_height * out_width)\n","            base_y0 = base + y0 * dim2\n","            base_y1 = base + y1 * dim2\n","            idx_a = base_y0 + x0\n","            idx_b = base_y1 + x0\n","            idx_c = base_y0 + x1\n","            idx_d = base_y1 + x1\n","\n","            # use indices to lookup pixels in the flat image and restore\n","            # channels dim\n","            im_flat = tf.reshape(im, tf.stack([-1, channels]))\n","            im_flat = tf.cast(im_flat, 'float32')\n","            ia = tf.gather(im_flat, idx_a)\n","            ib = tf.gather(im_flat, idx_b)\n","            ic = tf.gather(im_flat, idx_c)\n","            i_d = tf.gather(im_flat, idx_d)\n","\n","            # and finally calculate interpolated values\n","            x0_f = tf.cast(x0, 'float32')\n","            x1_f = tf.cast(x1, 'float32')\n","            y0_f = tf.cast(y0, 'float32')\n","            y1_f = tf.cast(y1, 'float32')\n","            wa = tf.expand_dims(((x1_f - x) * (y1_f - y)), 1)\n","            wb = tf.expand_dims(((x1_f - x) * (y - y0_f)), 1)\n","            wc = tf.expand_dims(((x - x0_f) * (y1_f - y)), 1)\n","            wd = tf.expand_dims(((x - x0_f) * (y - y0_f)), 1)\n","            output = tf.add_n([wa * ia, wb * ib, wc * ic, wd * i_d])\n","            return output\n","\n","    # input:  batch_size*(grid_h+1)*(grid_w+1)*2\n","    # output: batch_size*grid_h*grid_w*9\n","    def get_Hs(_theta, width, height):\n","        with tf.compat.v1.variable_scope('get_Hs'):\n","            num_batch = tf.shape(input=_theta)[0]\n","            h = height / grid_h\n","            w = width / grid_w\n","            hs = []\n","            for i in range(grid_h):\n","                for j in range(grid_w):\n","                    hh = i * h\n","                    ww = j * w\n","                    ori = tf.tile(tf.constant([ww, hh, ww + w, hh, ww, hh + h, ww + w, hh + h], shape=[1, 8],\n","                                              dtype=tf.float32), multiples=[num_batch, 1])\n","                    # id = i * (grid_w + 1) + grid_w\n","                    tar = tf.concat([tf.slice(_theta, [0, i, j, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i, j + 1, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i + 1, j, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i + 1, j + 1, 0], [-1, 1, 1, -1])], axis=1)\n","\n","                    tar = tf.reshape(tar, [num_batch, 8])\n","\n","                    # tar = tf.Print(tar, [tf.slice(ori, [0, 0], [1, -1])],message=\"[ori--i:\"+str(i)+\",j:\"+str(j)+\"]:\",\n","                    # summarize=100,first_n=5)\n","                    # tar = tf.Print(tar, [tf.slice(tar, [0, 0], [1, -1])],message=\"[tar--i:\"+str(i)+\",j:\"+str(j)+\"]:\",\n","                    # summarize=100,first_n=5)\n","\n","                    hs.append(tf.reshape(tensorDLT_local.solve_DLT(ori, tar), [num_batch, 1, 9]))\n","\n","            hs = tf.reshape(tf.concat(hs, axis=1), [num_batch, grid_h, grid_w, 9], name='Hs')\n","        return hs\n","\n","    def _mesh_grid(height, width):\n","\n","        x_t = tf.matmul(tf.ones(shape=tf.stack([height, 1])),\n","                        tf.transpose(a=tf.expand_dims(tf.linspace(0., tf.cast(width, 'float32') - 1.001, width), 1),\n","                                     perm=[1, 0]))\n","        y_t = tf.matmul(tf.expand_dims(tf.linspace(0., tf.cast(height, 'float32') - 1.001, height), 1),\n","                        tf.ones(shape=tf.stack([1, width])))\n","\n","        x_t_flat = tf.reshape(x_t, (1, -1))\n","        y_t_flat = tf.reshape(y_t, (1, -1))\n","\n","        ones = tf.ones_like(x_t_flat)\n","        grid = tf.concat([x_t_flat, y_t_flat, ones], 0)\n","\n","        return grid\n","\n","    def _transform3(_theta, input_dim, _mask):\n","        with tf.compat.v1.variable_scope('_transform'):\n","            num_batch = tf.shape(input=input_dim)[0]\n","            height = tf.shape(input=input_dim)[1]\n","            width = tf.shape(input=input_dim)[2]\n","            num_channels = tf.shape(input=input_dim)[3]\n","\n","            # the width/height should be an integral multiple of grid_w/grid_h\n","            width_float = 512.\n","            height_float = 384.\n","\n","            _theta = tf.cast(_theta, 'float32')\n","            h_s = get_Hs(_theta, width_float, height_float)\n","\n","            ##########################################\n","            print(\"Hs\")\n","            print(h_s.shape)\n","            h_array = UpSampling2D(size=(384 / grid_h, 512 / grid_w))(h_s)\n","            h_array = tf.reshape(h_array, [-1, 3, 3])\n","            ##########################################\n","\n","            out_height = height\n","            out_width = width\n","            grid = _mesh_grid(out_height, out_width)\n","            grid = tf.expand_dims(grid, 0)\n","            grid = tf.reshape(grid, [-1])\n","            grid = tf.tile(grid, tf.stack([num_batch]))  # stack num_batch grids\n","            grid = tf.reshape(grid, tf.stack([num_batch, 3, -1]))\n","            print(\"grid\")\n","            print(grid.shape)\n","            # [bs, 3, N]\n","\n","            grid = tf.expand_dims(tf.transpose(a=grid, perm=[0, 2, 1]), 3)\n","            # [bs, 3, N] -> [bs, N, 3] -> [bs, N, 3, 1]\n","            grid = tf.reshape(grid, [-1, 3, 1])\n","            # [bs*N, 3, 1]\n","\n","            grid_row = tf.reshape(grid, [-1, 3])\n","            print(\"grid_row\")\n","            print(grid_row.shape)\n","            x_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 0, :], grid_row), axis=1)\n","            y_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 1, :], grid_row), axis=1)\n","            t_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 2, :], grid_row), axis=1)\n","\n","            # The problem may be here as a general homo does not preserve the parallelism\n","            # while an affine transformation preserves it.\n","            t_s_flat = tf.reshape(t_s, [-1])\n","            t_1 = tf.ones(shape=tf.shape(input=t_s_flat))\n","            t_0 = tf.zeros(shape=tf.shape(input=t_s_flat))\n","            sign_t = tf.compat.v1.where(t_s_flat >= 0, t_1, t_0) * 2 - 1\n","            t_s_flat = t_s_flat + sign_t * 1e-8\n","\n","            x_s_flat = tf.reshape(x_s, [-1]) / t_s_flat\n","            y_s_flat = tf.reshape(y_s, [-1]) / t_s_flat\n","\n","            out_size = (height, width)\n","            input_transformed = _interpolate(input_dim, x_s_flat, y_s_flat, out_size)\n","            mask_transformed = _interpolate(_mask, x_s_flat, y_s_flat, out_size)\n","\n","            _warp_image = tf.reshape(input_transformed, tf.stack([num_batch, height, width, num_channels]),\n","                                     name='output_img')\n","            _warp_mask = tf.reshape(mask_transformed, tf.stack([num_batch, height, width, num_channels]),\n","                                    name='output_mask')\n","\n","            return _warp_image, _warp_mask\n","\n","    with tf.compat.v1.variable_scope(name):\n","        # output = _transform(theta, U, out_size)\n","        _u = _u - 1.\n","        warp_image, warp_mask = _transform3(theta, _u, mask)\n","        warp_image = warp_image + 1.\n","        warp_image = tf.clip_by_value(warp_image, -1, 1)\n","        return warp_image, warp_mask"],"metadata":{"id":"ME3pPRXQqDih","executionInfo":{"status":"ok","timestamp":1660385976306,"user_tz":-180,"elapsed":540,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","import tensorflow as tf\n","from keras.layers import UpSampling2D\n","\n","\n","grid_w = GRID_W\n","grid_h = GRID_H\n","\n","\n","def transformer_feature(_u, theta, name='SpatialTransformer'):\n","    def _repeat_feature(x, n_repeats):\n","        with tf.compat.v1.variable_scope('_repeat'):\n","            rep = tf.transpose(\n","                a=tf.expand_dims(tf.ones(shape=tf.stack([n_repeats, ])), 1), perm=[1, 0])\n","            rep = tf.cast(rep, 'int32')\n","            x = tf.matmul(tf.reshape(x, (-1, 1)), rep)\n","            return tf.reshape(x, [-1])\n","\n","    def _interpolate_feature(im, x, y, out_size):\n","        with tf.compat.v1.variable_scope('_interpolate'):\n","            # constants\n","            num_batch = tf.shape(input=im)[0]\n","            height = tf.shape(input=im)[1]\n","            width = tf.shape(input=im)[2]\n","            channels = tf.shape(input=im)[3]\n","\n","            x = tf.cast(x, 'float32')\n","            y = tf.cast(y, 'float32')\n","\n","            out_height = out_size[0]\n","            out_width = out_size[1]\n","            zero = tf.zeros([], dtype='int32')\n","            max_y = tf.cast(tf.shape(input=im)[1] - 1, 'int32')\n","            max_x = tf.cast(tf.shape(input=im)[2] - 1, 'int32')\n","\n","            # scale indices from [-1, 1] to [0, width/height]\n","            # x = (x + 1.0)*(width_f) / 2.0\n","            # y = (y + 1.0)*(height_f) / 2.0\n","\n","            # do sampling\n","            x0 = tf.cast(tf.floor(x), 'int32')\n","            x1 = x0 + 1\n","            y0 = tf.cast(tf.floor(y), 'int32')\n","            y1 = y0 + 1\n","\n","            x0 = tf.clip_by_value(x0, zero, max_x)\n","            x1 = tf.clip_by_value(x1, zero, max_x)\n","            y0 = tf.clip_by_value(y0, zero, max_y)\n","            y1 = tf.clip_by_value(y1, zero, max_y)\n","            dim2 = width\n","            dim1 = width * height\n","            base = _repeat_feature(tf.range(num_batch) * dim1, out_height * out_width)\n","            base_y0 = base + y0 * dim2\n","            base_y1 = base + y1 * dim2\n","            idx_a = base_y0 + x0\n","            idx_b = base_y1 + x0\n","            idx_c = base_y0 + x1\n","            idx_d = base_y1 + x1\n","\n","            # use indices to lookup pixels in the flat image and restore\n","            # channels dim\n","            im_flat = tf.reshape(im, tf.stack([-1, channels]))\n","            im_flat = tf.cast(im_flat, 'float32')\n","            ia = tf.gather(im_flat, idx_a)\n","            ib = tf.gather(im_flat, idx_b)\n","            ic = tf.gather(im_flat, idx_c)\n","            i_d = tf.gather(im_flat, idx_d)\n","\n","            # and finally calculate interpolated values\n","            x0_f = tf.cast(x0, 'float32')\n","            x1_f = tf.cast(x1, 'float32')\n","            y0_f = tf.cast(y0, 'float32')\n","            y1_f = tf.cast(y1, 'float32')\n","            wa = tf.expand_dims(((x1_f - x) * (y1_f - y)), 1)\n","            wb = tf.expand_dims(((x1_f - x) * (y - y0_f)), 1)\n","            wc = tf.expand_dims(((x - x0_f) * (y1_f - y)), 1)\n","            wd = tf.expand_dims(((x - x0_f) * (y - y0_f)), 1)\n","            output = tf.add_n([wa * ia, wb * ib, wc * ic, wd * i_d])\n","            return output\n","\n","    # input:  batch_size*(grid_h+1)*(grid_w+1)*2\n","    # output: batch_size*grid_h*grid_w*9\n","    def get_Hs_feature(_theta, width, height):\n","        with tf.compat.v1.variable_scope('get_Hs'):\n","            num_batch = tf.shape(input=_theta)[0]\n","            h = height / grid_h\n","            w = width / grid_w\n","            hs = []\n","            for i in range(grid_h):\n","                for j in range(grid_w):\n","                    hh = i * h\n","                    ww = j * w\n","                    ori = tf.tile(\n","                        tf.constant([ww, hh, ww + w, hh, ww, hh + h, ww + w, hh + h], shape=[1, 8], dtype=tf.float32),\n","                        multiples=[num_batch, 1])\n","                    # id = i * (grid_w + 1) + grid_w\n","                    tar = tf.concat([tf.slice(_theta, [0, i, j, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i, j + 1, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i + 1, j, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i + 1, j + 1, 0], [-1, 1, 1, -1])], axis=1)\n","\n","                    tar = tf.reshape(tar, [num_batch, 8])\n","\n","                    hs.append(tf.reshape(tensorDLT_local.solve_DLT(ori, tar), [num_batch, 1, 9]))\n","            hs = tf.reshape(tf.concat(hs, axis=1), [num_batch, grid_h, grid_w, 9], name='Hs')\n","        return hs\n","\n","    def _mesh_grid_feature(height, width):\n","        x_t = tf.matmul(tf.ones(shape=tf.stack([height, 1])),\n","                        tf.transpose(a=tf.expand_dims(tf.linspace(0., tf.cast(width, 'float32') - 1.001, width), 1),\n","                                     perm=[1, 0]))\n","        y_t = tf.matmul(tf.expand_dims(tf.linspace(0., tf.cast(height, 'float32') - 1.001, height), 1),\n","                        tf.ones(shape=tf.stack([1, width])))\n","\n","        x_t_flat = tf.reshape(x_t, (1, -1))\n","        y_t_flat = tf.reshape(y_t, (1, -1))\n","\n","        ones = tf.ones_like(x_t_flat)\n","        grid = tf.concat([x_t_flat, y_t_flat, ones], 0)\n","\n","        return grid\n","\n","    def _transform3_feature(_theta, input_dim):\n","        with tf.compat.v1.variable_scope('_transform'):\n","            num_batch = tf.shape(input=input_dim)[0]\n","            height = tf.shape(input=input_dim)[1]\n","            width = tf.shape(input=input_dim)[2]\n","            num_channels = tf.shape(input=input_dim)[3]\n","\n","            # the width/height should be an integral multiple of grid_w/grid_h\n","            width_float = 32.\n","            height_float = 24.\n","\n","            _theta = tf.cast(_theta, 'float32')\n","            hs = get_Hs_feature(_theta, width_float, height_float)\n","\n","            ##########################################\n","            print(\"Hs\")\n","            print(hs.shape)\n","            h_array = UpSampling2D(size=(24 / grid_h, 32 / grid_w))(hs)\n","            h_array = tf.reshape(h_array, [-1, 3, 3])\n","            ##########################################\n","\n","            out_height = height\n","            out_width = width\n","            grid = _mesh_grid_feature(out_height, out_width)\n","            grid = tf.expand_dims(grid, 0)\n","            grid = tf.reshape(grid, [-1])\n","            grid = tf.tile(grid, tf.stack([num_batch]))  # stack num_batch grids\n","            grid = tf.reshape(grid, tf.stack([num_batch, 3, -1]))\n","            print(\"grid\")\n","            print(grid.shape)\n","            # [bs, 3, N]\n","\n","            grid = tf.expand_dims(tf.transpose(a=grid, perm=[0, 2, 1]), 3)\n","            # [bs, 3, N] -> [bs, N, 3] -> [bs, N, 3, 1]\n","            grid = tf.reshape(grid, [-1, 3, 1])\n","            # [bs*N, 3, 1]\n","\n","            grid_row = tf.reshape(grid, [-1, 3])\n","            print(\"grid_row\")\n","            print(grid_row.shape)\n","            x_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 0, :], grid_row), axis=1)\n","            y_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 1, :], grid_row), axis=1)\n","            t_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 2, :], grid_row), axis=1)\n","\n","            # The problem may be here as a general homo does not preserve the parallelism\n","            # while an affine transformation preserves it.\n","            t_s_flat = tf.reshape(t_s, [-1])\n","            t_1 = tf.ones(shape=tf.shape(input=t_s_flat))\n","            t_0 = tf.zeros(shape=tf.shape(input=t_s_flat))\n","            sign_t = tf.compat.v1.where(t_s_flat >= 0, t_1, t_0) * 2 - 1\n","            t_s_flat = t_s_flat + sign_t * 1e-8\n","\n","            x_s_flat = tf.reshape(x_s, [-1]) / t_s_flat\n","            y_s_flat = tf.reshape(y_s, [-1]) / t_s_flat\n","\n","            out_size = (height, width)\n","            input_transformed = _interpolate_feature(input_dim, x_s_flat, y_s_flat, out_size)\n","            # mask_transformed = _interpolate(mask, x_s_flat, y_s_flat, out_size)\n","\n","            _warp_image = tf.reshape(input_transformed, tf.stack([num_batch, height, width, num_channels]),\n","                                     name='output_img')\n","\n","            return _warp_image\n","\n","    with tf.compat.v1.variable_scope(name):\n","        # output = _transform(theta, U, out_size)\n","        # U = U - 1.\n","        warp_image = _transform3_feature(theta, _u)\n","        # warp_image = warp_image + 1.\n","        # warp_image = tf.clip_by_value(warp_image, -1, 1)\n","        return warp_image"],"metadata":{"id":"EI8tte-tqfaT","executionInfo":{"status":"ok","timestamp":1660385976306,"user_tz":-180,"elapsed":4,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","grid_w = GRID_W\n","grid_h = GRID_H\n","\n","min_w = (512 / grid_w) / 8\n","min_h = (384 / grid_h) / 8\n","\n","\n","# pixel-level loss (l_num=1 for L1 loss, l_num=2 for L2 loss, ......)\n","def intensity_loss(gen_frames, gt_frames, l_num):\n","    return tf.reduce_mean(input_tensor=tf.abs((gen_frames - gt_frames) ** l_num))\n","\n","\n","# intra-grid constraint\n","def intra_grid_loss(pts):\n","    with tf.compat.v1.name_scope('soft_mesh_loss2'):\n","\n","        delta_x = pts[:, :, 0:grid_w, 0] - pts[:, :, 1:grid_w + 1, 0]\n","        delta_y = pts[:, 0:grid_h, :, 1] - pts[:, 1:grid_h + 1, :, 1]\n","\n","        loss_x = tf.nn.relu(delta_x + min_w)\n","        loss_y = tf.nn.relu(delta_y + min_h)\n","\n","        loss = tf.reduce_mean(input_tensor=loss_x) + tf.reduce_mean(input_tensor=loss_y)\n","\n","    return loss\n","\n","\n","# inter-grid constraint\n","def inter_grid_loss(train_mesh):\n","    w_edges = train_mesh[:, :, 0:grid_w, :] - train_mesh[:, :, 1:grid_w + 1, :]\n","    cos_w = tf.reduce_sum(input_tensor=w_edges[:, :, 0:grid_w - 1, :] * w_edges[:, :, 1:grid_w, :], axis=3) / (\n","                tf.sqrt(tf.reduce_sum(input_tensor=w_edges[:, :, 0:grid_w - 1, :] * w_edges[:, :, 0:grid_w - 1, :], axis=3)) * tf.sqrt(\n","                    tf.reduce_sum(input_tensor=w_edges[:, :, 1:grid_w, :] * w_edges[:, :, 1:grid_w, :], axis=3)))\n","    print(\"cos_w.shape\")\n","    print(cos_w.shape)\n","    delta_w_angle = 1 - cos_w\n","\n","    h_edges = train_mesh[:, 0:grid_h, :, :] - train_mesh[:, 1:grid_h + 1, :, :]\n","    cos_h = tf.reduce_sum(input_tensor=h_edges[:, 0:grid_h - 1, :, :] * h_edges[:, 1:grid_h, :, :], axis=3) / (\n","                tf.sqrt(tf.reduce_sum(input_tensor=h_edges[:, 0:grid_h - 1, :, :] * h_edges[:, 0:grid_h - 1, :, :], axis=3)) * tf.sqrt(\n","                    tf.reduce_sum(input_tensor=h_edges[:, 1:grid_h, :, :] * h_edges[:, 1:grid_h, :, :], axis=3)))\n","\n","    delta_h_angle = 1 - cos_h\n","\n","    loss = tf.reduce_mean(input_tensor=delta_w_angle) + tf.reduce_mean(input_tensor=delta_h_angle)\n","\n","    return loss"],"metadata":{"id":"SFxck1lSqnkf","executionInfo":{"status":"ok","timestamp":1660385976307,"user_tz":-180,"elapsed":4,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import tf_slim as slim\n","# from tensorflow.contrib.layers import conv2d\n","from tensorflow.nn import conv2d\n","\n","\n","grid_w = GRID_W\n","grid_h = GRID_H\n","\n","\n","def shift2mesh(mesh_shift, width, height):\n","    batch_size = tf.shape(input=mesh_shift)[0]\n","    h = height / grid_h\n","    w = width / grid_w\n","    ori_pt = []\n","    for i in range(grid_h + 1):\n","        for j in range(grid_w + 1):\n","            ww = j * w\n","            hh = i * h\n","            p = tf.constant([ww, hh], shape=[2], dtype=tf.float32)\n","            ori_pt.append(tf.expand_dims(p, 0))\n","    ori_pt = tf.concat(ori_pt, axis=0)\n","    ori_pt = tf.reshape(ori_pt, [grid_h + 1, grid_w + 1, 2])\n","    ori_pt = tf.tile(tf.expand_dims(ori_pt, 0), [batch_size, 1, 1, 1])\n","\n","    tar_pt = ori_pt + mesh_shift\n","    # tar_pt = tf.reshape(tar_pt, [batch_size, grid_h+1, grid_w+1, 2])\n","\n","    return tar_pt\n","\n","\n","def RectanglingNetwork(train_input, train_mask, width=512., height=384.):\n","    mesh_shift_primary, mesh_shift_final = build_model(train_input, train_mask)\n","\n","    mesh_primary = shift2mesh(mesh_shift_primary, width, height)\n","    mesh_final = shift2mesh(mesh_shift_final + mesh_shift_primary, width, height)\n","\n","    warp_image_primary, warp_mask_primary = tf_spatial_transform_local.transformer(train_input, train_mask,\n","                                                                                   mesh_primary)\n","    warp_image_final, warp_mask_final = tf_spatial_transform_local.transformer(train_input, train_mask, mesh_final)\n","\n","    return mesh_primary, warp_image_primary, warp_mask_primary, mesh_final, warp_image_final, warp_mask_final\n","\n","\n","# feature extraction module\n","def feature_extractor(image_tf):\n","    feature = []\n","    # 512*384\n","    with tf.compat.v1.variable_scope('conv_block1'):\n","        conv1 = conv2d(inputs=image_tf, num_outputs=64, kernel_size=3, rate=1, activation_fn=tf.nn.relu)\n","        conv1 = conv2d(inputs=conv1, num_outputs=64, kernel_size=3, rate=1, activation_fn=tf.nn.relu)\n","        maxpool1 = slim.max_pool2d(conv1, 2, stride=2, padding='SAME')\n","    # 256*192\n","    with tf.compat.v1.variable_scope('conv_block2'):\n","        conv2 = conv2d(inputs=maxpool1, num_outputs=64, kernel_size=3, activation_fn=tf.nn.relu)\n","        conv2 = conv2d(inputs=conv2, num_outputs=64, kernel_size=3, activation_fn=tf.nn.relu)\n","        maxpool2 = slim.max_pool2d(conv2, 2, stride=2, padding='SAME')\n","    # 128*96\n","    with tf.compat.v1.variable_scope('conv_block3'):\n","        conv3 = conv2d(inputs=maxpool2, num_outputs=128, kernel_size=3, activation_fn=tf.nn.relu)\n","        conv3 = conv2d(inputs=conv3, num_outputs=128, kernel_size=3, activation_fn=tf.nn.relu)\n","        maxpool3 = slim.max_pool2d(conv3, 2, stride=2, padding='SAME')\n","    # 64*48\n","    with tf.compat.v1.variable_scope('conv_block4'):\n","        conv4 = conv2d(inputs=maxpool3, num_outputs=128, kernel_size=3, activation_fn=tf.nn.relu)\n","        conv4 = conv2d(inputs=conv4, num_outputs=128, kernel_size=3, activation_fn=tf.nn.relu)\n","        feature.append(conv4)\n","\n","    return feature\n","\n","\n","# mesh motion regression module\n","def regression_Net(correlation):\n","    conv1 = conv2d(inputs=correlation, num_outputs=256, kernel_size=3, activation_fn=tf.nn.relu)\n","    conv1 = conv2d(inputs=conv1, num_outputs=256, kernel_size=3, activation_fn=tf.nn.relu)\n","\n","    maxpool1 = slim.max_pool2d(conv1, 2, stride=2, padding='SAME')  # 16\n","    conv2 = conv2d(inputs=maxpool1, num_outputs=256, kernel_size=3, activation_fn=tf.nn.relu)\n","    conv2 = conv2d(inputs=conv2, num_outputs=256, kernel_size=3, activation_fn=tf.nn.relu)\n","\n","    maxpool2 = slim.max_pool2d(conv2, 2, stride=2, padding='SAME')  # 8\n","    conv3 = conv2d(inputs=maxpool2, num_outputs=512, kernel_size=3, activation_fn=tf.nn.relu)\n","    conv3 = conv2d(inputs=conv3, num_outputs=512, kernel_size=3, activation_fn=tf.nn.relu)\n","\n","    maxpool3 = slim.max_pool2d(conv3, 2, stride=2, padding='SAME')  # 4\n","    conv4 = conv2d(inputs=maxpool3, num_outputs=512, kernel_size=3, activation_fn=tf.nn.relu)\n","    conv4 = conv2d(inputs=conv4, num_outputs=512, kernel_size=3, activation_fn=tf.nn.relu)\n","\n","    fc1 = conv2d(inputs=conv4, num_outputs=2048, kernel_size=[3, 4], activation_fn=tf.nn.relu, padding=\"VALID\")\n","    fc2 = conv2d(inputs=fc1, num_outputs=1024, kernel_size=1, activation_fn=tf.nn.relu)\n","    fc3 = conv2d(inputs=fc2, num_outputs=(grid_w + 1) * (grid_h + 1) * 2, kernel_size=1, activation_fn=None)\n","    # net3_f = tf.expand_dims(tf.squeeze(tf.squeeze(fc3,1),1), [2])\n","    net3_f_local = tf.reshape(fc3, (-1, grid_h + 1, grid_w + 1, 2))\n","\n","    return net3_f_local\n","\n","\n","def build_model(train_input, train_mask):\n","    with tf.compat.v1.variable_scope('model'):\n","\n","        with tf.compat.v1.variable_scope('feature_extract', reuse=None):\n","            features = feature_extractor(tf.concat([train_input, train_mask], axis=3))\n","\n","        feature = tf.image.resize(features[-1], [24, 32], method=0)\n","        with tf.compat.v1.variable_scope('regression_coarse', reuse=None):\n","            mesh_shift_primary = regression_Net(feature)\n","\n","        with tf.compat.v1.variable_scope('regression_fine', reuse=None):\n","            mesh_primary = shift2mesh(mesh_shift_primary / 16, 32., 24.)\n","            feature_warp = tf_spatial_transform_local_feature.transformer_feature(feature, mesh_primary)\n","            mesh_shift_final = regression_Net(feature_warp)\n","\n","        return mesh_shift_primary, mesh_shift_final"],"metadata":{"id":"DbsDzUkxqv5Y","executionInfo":{"status":"ok","timestamp":1660385977264,"user_tz":-180,"elapsed":536,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from collections import OrderedDict\n","import sys\n","import os\n","import glob\n","import cv2\n","\n","rng = np.random.RandomState(2017)\n","\n","\n","class DataLoader(object):\n","    def __init__(self, data_folder):\n","        self.dir = data_folder\n","        self.datas = OrderedDict()\n","        self.setup()\n","\n","    def __call__(self, batch_size):\n","        data_info_list = list(self.datas.values())\n","        length = data_info_list[0]['length']\n","\n","        def data_clip_generator():\n","            while True:\n","                data_clip = []\n","                frame_id = rng.randint(0, length - 1)\n","                # inputs\n","\n","                input_img = np_load_frame(data_info_list[1]['frame'][frame_id], 384, 512)\n","                mask_img = np_load_frame(data_info_list[2]['frame'][frame_id], 384, 512)\n","                gt_img = np_load_frame(data_info_list[0]['frame'][frame_id], 384, 512)\n","\n","                data_clip.append(input_img)\n","                data_clip.append(mask_img)\n","                data_clip.append(gt_img)\n","                data_clip = np.concatenate(data_clip, axis=2)\n","\n","                yield data_clip\n","\n","                # creating augmentations\n","\n","                data_clip = []\n","\n","                flipped_input = np.fliplr(input_img)\n","                flipped_mask = np.fliplr(mask_img)\n","                flipped_gt = np.fliplr(gt_img)\n","\n","                data_clip.append(flipped_input)\n","                data_clip.append(flipped_mask)\n","                data_clip.append(flipped_gt)\n","                data_clip = np.concatenate(data_clip, axis=2)\n","\n","                yield data_clip\n","\n","        dataset = tf.data.Dataset.from_generator(generator=data_clip_generator, output_types=tf.float32,\n","                                                 output_shapes=[384, 512, 9])\n","\n","        print('generator dataset, {}'.format(dataset))\n","        dataset = dataset.prefetch(buffer_size=128)\n","        dataset = dataset.shuffle(buffer_size=128).batch(batch_size)\n","        print('epoch dataset, {}'.format(dataset))\n","\n","        return dataset\n","\n","    def __getitem__(self, data_name):\n","        assert data_name in self.datas.keys(), 'data = {} is not in {}!'.format(data_name, self.datas.keys())\n","        return self.datas[data_name]\n","\n","    def setup(self):\n","        datas = glob.glob(os.path.join(self.dir, '*'))\n","        for data in sorted(datas):\n","\n","            if sys.platform[:3] == 'win':\n","                data_name = data.split('\\\\')[-1]\n","            else:\n","                data_name = data.split('/')[-1]\n","\n","            if data_name == 'gt' or data_name == 'input' or data_name == 'mask':\n","                self.datas[data_name] = {}\n","                self.datas[data_name]['path'] = data\n","                self.datas[data_name]['frame'] = glob.glob(os.path.join(data, '*.jpg'))\n","                self.datas[data_name]['frame'].sort()\n","                self.datas[data_name]['length'] = len(self.datas[data_name]['frame'])\n","\n","        print(self.datas.keys())\n","\n","    def get_data_clips(self, index):\n","        batch = []\n","        data_info_list = list(self.datas.values())\n","\n","        batch.append(np_load_frame(data_info_list[1]['frame'][index], 384, 512))\n","        batch.append(np_load_frame(data_info_list[2]['frame'][index], 384, 512))\n","        batch.append(np_load_frame(data_info_list[0]['frame'][index], 384, 512))\n","\n","        return np.concatenate(batch, axis=2)\n","\n","\n","def np_load_frame(filename, resize_height, resize_width):\n","    image_decoded = cv2.imread(filename)\n","\n","    if resize_height is not None:\n","        image_resized = cv2.resize(image_decoded, (resize_width, resize_height))\n","    else:\n","        image_resized = image_decoded\n","\n","    image_resized = image_resized.astype(dtype=np.float32)\n","    image_resized = (image_resized / 127.5) - 1.0\n","    return image_resized\n","\n","\n","def load(saver, sess, ckpt_path):\n","    print(ckpt_path)\n","    saver.restore(sess, ckpt_path)\n","    print(\"Restored model parameters from {}\".format(ckpt_path))\n","\n","\n","def save(saver, sess, logdir, step):\n","    model_name = 'model.ckpt'\n","    checkpoint_path = os.path.join(logdir, model_name)\n","    if not os.path.exists(logdir):\n","        os.makedirs(logdir)\n","    saver.save(sess, checkpoint_path, global_step=step, save_format='h5')\n","    print('The checkpoint has been created.')"],"metadata":{"id":"U-xFtQunq9hF","executionInfo":{"status":"ok","timestamp":1660385977680,"user_tz":-180,"elapsed":417,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import os\n","import numpy as np\n","import cv2 as cv\n","\n","os.environ['CUDA_DEVICES_ORDER'] = \"PCI_BUS_ID\"\n","os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n","\n","test_folder = TEST_FOLDER\n","batch_size = TEST_BATCH_SIZE\n","grid_w = GRID_W\n","grid_h = GRID_H\n","\n","\n","def draw_mesh_on_warp(warp, f_local):\n","    min_w = np.minimum(np.min(f_local[:, :, 0]), 0).astype(np.int32)\n","    max_w = np.maximum(np.max(f_local[:, :, 0]), 512).astype(np.int32)\n","    min_h = np.minimum(np.min(f_local[:, :, 1]), 0).astype(np.int32)\n","    max_h = np.maximum(np.max(f_local[:, :, 1]), 384).astype(np.int32)\n","    cw = max_w - min_w\n","    ch = max_h - min_h\n","\n","    pic = np.ones([ch + 10, cw + 10, 3], np.int32) * 255\n","    pic[0 - min_h + 5:0 - min_h + 384 + 5, 0 - min_w + 5:0 - min_w + 512 + 5, :] = warp\n","\n","    warp = pic\n","    f_local[:, :, 0] = f_local[:, :, 0] - min_w + 5\n","    f_local[:, :, 1] = f_local[:, :, 1] - min_h + 5\n","\n","    point_color = (0, 255, 0)  # BGR\n","    thickness = 2\n","    line_type = 8\n","    num = 1\n","\n","    for i in range(grid_h + 1):\n","        for j in range(grid_w + 1):\n","            num = num + 1\n","            if j == grid_w and i == grid_h:\n","                continue\n","            elif j == grid_w:\n","                cv.line(warp, (f_local[i, j, 0], f_local[i, j, 1]), (f_local[i + 1, j, 0], f_local[i + 1, j, 1]),\n","                        point_color, thickness, line_type)\n","            elif i == grid_h:\n","                cv.line(warp, (f_local[i, j, 0], f_local[i, j, 1]), (f_local[i, j + 1, 0], f_local[i, j + 1, 1]),\n","                        point_color, thickness, line_type)\n","            else:\n","                cv.line(warp, (f_local[i, j, 0], f_local[i, j, 1]), (f_local[i + 1, j, 0], f_local[i + 1, j, 1]),\n","                        point_color, thickness, line_type)\n","                cv.line(warp, (f_local[i, j, 0], f_local[i, j, 1]), (f_local[i, j + 1, 0], f_local[i, j + 1, 1]),\n","                        point_color, thickness, line_type)\n","\n","    return warp\n","\n","\n","snapshot_dir = '/content/drive/MyDrive/Colab Notebooks/checkpoints/pretrained_model/model.ckpt-100000'\n","\n","# define dataset\n","with tf.compat.v1.name_scope('dataset'):\n","    # ----------- testing ----------- #\n","    tf.compat.v1.disable_eager_execution()\n","    test_inputs_clips_tensor = tf.compat.v1.placeholder(shape=[batch_size, None, None, 3 * 3], dtype=tf.float32)\n","\n","    test_input = test_inputs_clips_tensor[..., 0:3]\n","    test_mask = test_inputs_clips_tensor[..., 3:6]\n","    test_gt = test_inputs_clips_tensor[..., 6:9]\n","\n","    print('test input = {}'.format(test_input))\n","    print('test mask = {}'.format(test_mask))\n","    print('test gt = {}'.format(test_gt))\n","\n","# define testing generator function\n","with tf.compat.v1.variable_scope('generator', reuse=None):\n","    print('testing = {}'.format(tf.compat.v1.get_variable_scope().name))\n","    test_mesh_primary, test_warp_image_primary, test_warp_mask_primary, test_mesh_final, test_warp_image_final, \\\n","        test_warp_mask_final = RectanglingNetwork(test_input, test_mask)\n","\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","with tf.compat.v1.Session(config=config) as sess:\n","    # dataset\n","    input_loader = DataLoader(test_folder)\n","\n","    # initialize weights\n","    sess.run(tf.compat.v1.global_variables_initializer())\n","    print('Init global successfully!')\n","\n","    # tf saver\n","    saver = tf.compat.v1.train.Saver(var_list=tf.compat.v1.global_variables(), max_to_keep=None)\n","\n","    restore_var = [v for v in tf.compat.v1.global_variables()]\n","    loader = tf.compat.v1.train.Saver(var_list=restore_var)\n","\n","\n","    def inference_func(ckpt):\n","        print(\"============\")\n","        print(ckpt)\n","        load(loader, sess, ckpt)\n","        print(\"============\")\n","        length = 519  # len(os.listdir(test_folder+\"/input\"))\n","\n","        for i in range(0, length):\n","            input_clip = np.expand_dims(input_loader.get_data_clips(i), axis=0)\n","\n","            mesh_primary, warp_image_primary, warp_mask_primary, mesh_final, warp_image_final, warp_mask_final = \\\n","                sess.run([test_mesh_primary, test_warp_image_primary, test_warp_mask_primary, test_mesh_final,\n","                          test_warp_image_final, test_warp_mask_final],\n","                         feed_dict={test_inputs_clips_tensor: input_clip})\n","\n","            mesh = mesh_final[0]\n","            input_image = (input_clip[0, :, :, 0:3] + 1) / 2 * 255\n","\n","            input_image = draw_mesh_on_warp(input_image, mesh)\n","            # input_mask = draw_mesh_on_warp(np.ones([384, 512, 3], np.int32)*255, mesh)\n","\n","            path = \"../final_mesh/\" + str(i + 1).zfill(5) + \".jpg\"\n","            cv.imwrite(path, input_image)\n","\n","            # path = \"../mesh_mask/\" + str(i+1).zfill(5) + \".jpg\"\n","            # cv.imwrite(path, input_mask)\n","\n","            print('i = {} / {}'.format(i + 1, length))\n","\n","\n","    inference_func(snapshot_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"g0oVgzWArD22","executionInfo":{"status":"error","timestamp":1660385978094,"user_tz":-180,"elapsed":417,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}},"outputId":"74091cf2-1ddc-4c8b-ab4a-a1608fe307f4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["test input = Tensor(\"strided_slice:0\", shape=(1, None, None, 3), dtype=float32)\n","test mask = Tensor(\"strided_slice_1:0\", shape=(1, None, None, 3), dtype=float32)\n","test gt = Tensor(\"strided_slice_2:0\", shape=(1, None, None, 3), dtype=float32)\n","testing = generator\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-a7d67f713f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generator'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testing = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mtest_mesh_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_warp_image_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_warp_mask_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mesh_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_warp_image_final\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0mtest_warp_mask_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRectanglingNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-520f2aeea3f8>\u001b[0m in \u001b[0;36mRectanglingNetwork\u001b[0;34m(train_input, train_mask, width, height)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mRectanglingNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m384.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmesh_shift_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh_shift_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmesh_primary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift2mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_shift_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-520f2aeea3f8>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(train_input, train_mask)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_extract'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-520f2aeea3f8>\u001b[0m in \u001b[0;36mfeature_extractor\u001b[0;34m(image_tf)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# 512*384\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv_block1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mmaxpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miterable_params\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace_iterable_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_dispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Got an unexpected keyword argument 'inputs'"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import os\n","import cv2\n","import skimage\n","from skimage import metrics\n","\n","os.environ['CUDA_DEVICES_ORDER'] = \"PCI_BUS_ID\"\n","os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n","\n","test_folder = TEST_FOLDER\n","batch_size = TEST_BATCH_SIZE\n","\n","snapshot_dir = SNAPSHOT_DIR + '/pretrained_model/model.ckpt-100000'\n","\n","# define dataset\n","with tf.compat.v1.name_scope('dataset'):\n","    # --------- testing --------- #\n","    test_inputs_clips_tensor = tf.compat.v1.placeholder(shape=[batch_size, None, None, 3 * 3], dtype=tf.float32)\n","\n","    test_input = test_inputs_clips_tensor[..., 0:3]\n","    test_mask = test_inputs_clips_tensor[..., 3:6]\n","    test_gt = test_inputs_clips_tensor[..., 6:9]\n","\n","    print('test input = {}'.format(test_input))\n","    print('test mask = {}'.format(test_mask))\n","    print('test gt = {}'.format(test_gt))\n","\n","# define testing generator function \n","with tf.compat.v1.variable_scope('generator', reuse=None):\n","    print('testing = {}'.format(tf.compat.v1.get_variable_scope().name))\n","    test_mesh_primary, test_warp_image_primary, test_warp_mask_primary, test_mesh_final, test_warp_image_final, \\\n","        test_warp_mask_final = RectanglingNetwork(test_input, test_mask)\n","\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","with tf.compat.v1.Session(config=config) as sess:\n","    # dataset\n","    input_loader = DataLoader(test_folder)\n","\n","    # initialize weights\n","    sess.run(tf.compat.v1.global_variables_initializer())\n","    print('Init global successfully!')\n","\n","    # tf saver\n","    saver = tf.compat.v1.train.Saver(var_list=tf.compat.v1.global_variables(), max_to_keep=None)\n","\n","    restore_var = [v for v in tf.compat.v1.global_variables()]\n","    loader = tf.compat.v1.train.Saver(var_list=restore_var)\n","\n","\n","    def inference_func(ckpt):\n","        print(\"============\")\n","        print(ckpt)\n","        load(loader, sess, ckpt)\n","        print(\"============\")\n","        length = 519  # len(os.listdir(test_folder+\"/input\"))\n","        psnr_list = []\n","        ssim_list = []\n","\n","        for i in range(0, length):\n","            input_clip = np.expand_dims(input_loader.get_data_clips(i), axis=0)\n","\n","            mesh_primary, warp_image_primary, warp_mask_primary, mesh_final, warp_image_final, warp_mask_final = \\\n","                sess.run([test_mesh_primary, test_warp_image_primary, test_warp_mask_primary, test_mesh_final,\n","                          test_warp_image_final, test_warp_mask_final],\n","                         feed_dict={test_inputs_clips_tensor: input_clip})\n","\n","            warp_image = (warp_image_final[0] + 1) * 127.5\n","            warp_gt = (input_clip[0, :, :, 6:9] + 1) * 127.5\n","\n","            psnr = skimage.metrics.peak_signal_noise_ratio(warp_image, warp_gt, data_range=255)\n","            ssim = skimage.metrics.structural_similarity(warp_image, warp_gt, data_range=255, multichannel=True)\n","\n","            path = \"../final_rectangling/\" + str(i + 1).zfill(5) + \".jpg\"\n","            cv2.imwrite(path, warp_image)\n","\n","            print('i = {} / {}, psnr = {:.6f}'.format(i + 1, length, psnr))\n","\n","            psnr_list.append(psnr)\n","            ssim_list.append(ssim)\n","\n","        print(\"===================Results Analysis==================\")\n","        print('average psnr:', np.mean(psnr_list))\n","        print('average ssim:', np.mean(ssim_list))\n","        # as for FID, we use the CODE from https://github.com/bioinf-jku/TTUR to evaluate\n","\n","\n","    inference_func(snapshot_dir)"],"metadata":{"id":"Vl2r8zOKrF2Z","executionInfo":{"status":"aborted","timestamp":1660385978094,"user_tz":-180,"elapsed":3,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}}},"execution_count":null,"outputs":[]}]}