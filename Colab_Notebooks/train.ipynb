{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[{"file_id":"1zhUCdaOg7MtU2oH2gSc51Cg4Zz2iRV_r","timestamp":1660385801479}],"collapsed_sections":[],"mount_file_id":"17jM1F10lendaW44e6Ge7XwMDVmzZDjRm","authorship_tag":"ABX9TyPf4A7OK7OdBTyrTrA359cn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install tf_slim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kIQ08A1rqRB","executionInfo":{"status":"ok","timestamp":1660670600544,"user_tz":-180,"elapsed":5374,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}},"outputId":"d7ee62f8-7661-40bb-eb18-7657b04e9cd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tf_slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 17.0 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (1.2.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ZMNybc6adph"},"outputs":[],"source":["# training dataset path\n","TRAIN_FOLDER = '/content/drive/MyDrive/Colab Notebooks/DIR-D/training'\n","\n","# testing dataset path\n","TEST_FOLDER = '/content/drive/MyDrive/Colab Notebooks/DIR-D/testing'\n","\n","# GPU index\n","GPU = '0'\n","\n","# batch size for training\n","TRAIN_BATCH_SIZE = 1\n","\n","# batch size for testing\n","TEST_BATCH_SIZE = 1\n","\n","# num of iterations\n","ITERATIONS = 100000\n","\n","# checkpoints path\n","SNAPSHOT_DIR = \"/content/drive/MyDrive/Colab Notebooks/checkpoints\"\n","\n","# summary path\n","SUMMARY_DIR = \"/content/drive/MyDrive/Colab Notebooks/summary\"\n","\n","# define the mesh resolution\n","GRID_W = 8\n","GRID_H = 6"]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","#######################################################\n","# Auxiliary matrices used to solve DLT\n","Aux_M1 = np.array([\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 1, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 1, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 1, 0]], dtype=np.float64)\n","\n","Aux_M2 = np.array([\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 1, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 1, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 1, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 1]], dtype=np.float64)\n","\n","Aux_M3 = np.array([\n","    [0],\n","    [1],\n","    [0],\n","    [1],\n","    [0],\n","    [1],\n","    [0],\n","    [1]], dtype=np.float64)\n","\n","Aux_M4 = np.array([\n","    [-1, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, -1, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, -1, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, -1, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0]], dtype=np.float64)\n","\n","Aux_M5 = np.array([\n","    [0, -1, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, -1, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, -1, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, -1],\n","    [0, 0, 0, 0, 0, 0, 0, 0]], dtype=np.float64)\n","\n","Aux_M6 = np.array([\n","    [-1],\n","    [0],\n","    [-1],\n","    [0],\n","    [-1],\n","    [0],\n","    [-1],\n","    [0]], dtype=np.float64)\n","\n","Aux_M71 = np.array([\n","    [0, 1, 0, 0, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 1, 0, 0, 0, 0],\n","    [0, 0, 1, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 1, 0, 0],\n","    [0, 0, 0, 0, 1, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 1],\n","    [0, 0, 0, 0, 0, 0, 1, 0]], dtype=np.float64)\n","\n","Aux_M72 = np.array([\n","    [1, 0, 0, 0, 0, 0, 0, 0],\n","    [-1, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 1, 0, 0, 0, 0, 0],\n","    [0, 0, -1, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 1, 0, 0, 0],\n","    [0, 0, 0, 0, -1, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 1, 0],\n","    [0, 0, 0, 0, 0, 0, -1, 0]], dtype=np.float64)\n","\n","Aux_M8 = np.array([\n","    [0, 1, 0, 0, 0, 0, 0, 0],\n","    [0, -1, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 1, 0, 0, 0, 0],\n","    [0, 0, 0, -1, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 1, 0, 0],\n","    [0, 0, 0, 0, 0, -1, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, 1],\n","    [0, 0, 0, 0, 0, 0, 0, -1]], dtype=np.float64)\n","\n","Aux_Mb = np.array([\n","    [0, -1, 0, 0, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0, 0, 0, 0],\n","    [0, 0, 0, -1, 0, 0, 0, 0],\n","    [0, 0, 1, 0, 0, 0, 0, 0],\n","    [0, 0, 0, 0, 0, -1, 0, 0],\n","    [0, 0, 0, 0, 1, 0, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0, -1],\n","    [0, 0, 0, 0, 0, 0, 1, 0]], dtype=np.float64)\n","\n","\n","########################################################\n","\n","def solve_DLT(orig_pt4, pred_pt4):\n","    batch_size = tf.shape(input=orig_pt4)[0]\n","    orig_pt4 = tf.expand_dims(orig_pt4, [2])\n","    pred_pt4 = tf.expand_dims(pred_pt4, [2])\n","\n","    # Auxiliary tensors used to create Ax = b equation\n","    m1 = tf.constant(Aux_M1, tf.float32)\n","    m1_tensor = tf.expand_dims(m1, [0])\n","    m1_tile = tf.tile(m1_tensor, [batch_size, 1, 1])\n","\n","    m2 = tf.constant(Aux_M2, tf.float32)\n","    m2_tensor = tf.expand_dims(m2, [0])\n","    m2_tile = tf.tile(m2_tensor, [batch_size, 1, 1])\n","\n","    m3 = tf.constant(Aux_M3, tf.float32)\n","    m3_tensor = tf.expand_dims(m3, [0])\n","    m3_tile = tf.tile(m3_tensor, [batch_size, 1, 1])\n","\n","    m4 = tf.constant(Aux_M4, tf.float32)\n","    m4_tensor = tf.expand_dims(m4, [0])\n","    m4_tile = tf.tile(m4_tensor, [batch_size, 1, 1])\n","\n","    m5 = tf.constant(Aux_M5, tf.float32)\n","    m5_tensor = tf.expand_dims(m5, [0])\n","    m5_tile = tf.tile(m5_tensor, [batch_size, 1, 1])\n","\n","    m6 = tf.constant(Aux_M6, tf.float32)\n","    m6_tensor = tf.expand_dims(m6, [0])\n","    m6_tile = tf.tile(m6_tensor, [batch_size, 1, 1])\n","\n","    m71 = tf.constant(Aux_M71, tf.float32)\n","    m71_tensor = tf.expand_dims(m71, [0])\n","    m71_tile = tf.tile(m71_tensor, [batch_size, 1, 1])\n","\n","    m72 = tf.constant(Aux_M72, tf.float32)\n","    m72_tensor = tf.expand_dims(m72, [0])\n","    m72_tile = tf.tile(m72_tensor, [batch_size, 1, 1])\n","\n","    m8 = tf.constant(Aux_M8, tf.float32)\n","    m8_tensor = tf.expand_dims(m8, [0])\n","    m8_tile = tf.tile(m8_tensor, [batch_size, 1, 1])\n","\n","    mb = tf.constant(Aux_Mb, tf.float32)\n","    mb_tensor = tf.expand_dims(mb, [0])\n","    mb_tile = tf.tile(mb_tensor, [batch_size, 1, 1])\n","\n","    # Form the equations Ax = b to compute H\n","    # Form A matrix\n","    a1 = tf.matmul(m1_tile, orig_pt4)  # Column 1\n","    a2 = tf.matmul(m2_tile, orig_pt4)  # Column 2\n","    a3 = m3_tile  # Column 3\n","    a4 = tf.matmul(m4_tile, orig_pt4)  # Column 4\n","    a5 = tf.matmul(m5_tile, orig_pt4)  # Column 5\n","    a6 = m6_tile  # Column 6\n","    a7 = tf.matmul(m71_tile, pred_pt4) * tf.matmul(m72_tile, orig_pt4)  # Column 7\n","    a8 = tf.matmul(m71_tile, pred_pt4) * tf.matmul(m8_tile, orig_pt4)  # Column 8\n","\n","    # tmp = tf.reshape(a1, [-1, 8])  #batch_size * 8\n","    # A_mat: batch_size * 8 * 8          a1-A8相当�?*8中的每一�?\n","    a_mat = tf.transpose(a=tf.stack([tf.reshape(a1, [-1, 8]), tf.reshape(a2, [-1, 8]),\n","                                   tf.reshape(a3, [-1, 8]), tf.reshape(a4, [-1, 8]),\n","                                   tf.reshape(a5, [-1, 8]), tf.reshape(a6, [-1, 8]),\n","                                   tf.reshape(a7, [-1, 8]), tf.reshape(a8, [-1, 8])], axis=1),\n","                         perm=[0, 2, 1])  # BATCH_SIZE x 8 (A_i) x 8\n","    print('--Shape of A_mat:', a_mat.get_shape().as_list())\n","    # Form b matrix\n","    b_mat = tf.matmul(mb_tile, pred_pt4)\n","    print('--shape of b:', b_mat.get_shape().as_list())\n","\n","    # Solve the Ax = b\n","    h_8el = tf.linalg.solve(a_mat, b_mat)  # BATCH_SIZE x 8.\n","    print('--shape of H_8el', h_8el)\n","\n","    # Add ones to the last cols to reconstruct H for computing reprojection error\n","    h_ones = tf.ones([batch_size, 1, 1])\n","    h_9el = tf.concat([h_8el, h_ones], 1)\n","    h_flat = tf.reshape(h_9el, [-1, 9])\n","    # H_mat = tf.reshape(h_flat ,[-1 ,3 ,3])   # BATCH_SIZE x 3 x 3\n","    return h_flat"],"metadata":{"id":"EpbN5g05p7ux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","import tensorflow as tf\n","from keras.layers import UpSampling2D\n","\n","grid_w = GRID_W\n","grid_h = GRID_H\n","\n","\n","def transformer(_u, mask, theta, name='SpatialTransformer'):\n","    def _repeat(x, n_repeats):\n","        with tf.compat.v1.variable_scope('_repeat'):\n","            rep = tf.transpose(\n","                a=tf.expand_dims(tf.ones(shape=tf.stack([n_repeats, ])), 1), perm=[1, 0])\n","            rep = tf.cast(rep, 'int32')\n","            x = tf.matmul(tf.reshape(x, (-1, 1)), rep)\n","            return tf.reshape(x, [-1])\n","\n","    def _interpolate(im, x, y, out_size):\n","        with tf.compat.v1.variable_scope('_interpolate'):\n","            # constants\n","            num_batch = tf.shape(input=im)[0]\n","            height = tf.shape(input=im)[1]\n","            width = tf.shape(input=im)[2]\n","            channels = tf.shape(input=im)[3]\n","\n","            x = tf.cast(x, 'float32')\n","            y = tf.cast(y, 'float32')\n","\n","            out_height = out_size[0]\n","            out_width = out_size[1]\n","            zero = tf.zeros([], dtype='int32')\n","            max_y = tf.cast(tf.shape(input=im)[1] - 1, 'int32')\n","            max_x = tf.cast(tf.shape(input=im)[2] - 1, 'int32')\n","\n","            # scale indices from [-1, 1] to [0, width/height]\n","            # x = (x + 1.0)*(width_f) / 2.0\n","            # y = (y + 1.0)*(height_f) / 2.0\n","\n","            # do sampling\n","            x0 = tf.cast(tf.floor(x), 'int32')\n","            x1 = x0 + 1\n","            y0 = tf.cast(tf.floor(y), 'int32')\n","            y1 = y0 + 1\n","\n","            x0 = tf.clip_by_value(x0, zero, max_x)\n","            x1 = tf.clip_by_value(x1, zero, max_x)\n","            y0 = tf.clip_by_value(y0, zero, max_y)\n","            y1 = tf.clip_by_value(y1, zero, max_y)\n","            dim2 = width\n","            dim1 = width * height\n","            base = _repeat(tf.range(num_batch) * dim1, out_height * out_width)\n","            base_y0 = base + y0 * dim2\n","            base_y1 = base + y1 * dim2\n","            idx_a = base_y0 + x0\n","            idx_b = base_y1 + x0\n","            idx_c = base_y0 + x1\n","            idx_d = base_y1 + x1\n","\n","            # use indices to lookup pixels in the flat image and restore\n","            # channels dim\n","            im_flat = tf.reshape(im, tf.stack([-1, channels]))\n","            im_flat = tf.cast(im_flat, 'float32')\n","            ia = tf.gather(im_flat, idx_a)\n","            ib = tf.gather(im_flat, idx_b)\n","            ic = tf.gather(im_flat, idx_c)\n","            i_d = tf.gather(im_flat, idx_d)\n","\n","            # and finally calculate interpolated values\n","            x0_f = tf.cast(x0, 'float32')\n","            x1_f = tf.cast(x1, 'float32')\n","            y0_f = tf.cast(y0, 'float32')\n","            y1_f = tf.cast(y1, 'float32')\n","            wa = tf.expand_dims(((x1_f - x) * (y1_f - y)), 1)\n","            wb = tf.expand_dims(((x1_f - x) * (y - y0_f)), 1)\n","            wc = tf.expand_dims(((x - x0_f) * (y1_f - y)), 1)\n","            wd = tf.expand_dims(((x - x0_f) * (y - y0_f)), 1)\n","            output = tf.add_n([wa * ia, wb * ib, wc * ic, wd * i_d])\n","            return output\n","\n","    # input:  batch_size*(grid_h+1)*(grid_w+1)*2\n","    # output: batch_size*grid_h*grid_w*9\n","    def get_Hs(_theta, width, height):\n","        with tf.compat.v1.variable_scope('get_Hs'):\n","            num_batch = tf.shape(input=_theta)[0]\n","            h = height / grid_h\n","            w = width / grid_w\n","            hs = []\n","            for i in range(grid_h):\n","                for j in range(grid_w):\n","                    hh = i * h\n","                    ww = j * w\n","                    ori = tf.tile(tf.constant([ww, hh, ww + w, hh, ww, hh + h, ww + w, hh + h], shape=[1, 8],\n","                                              dtype=tf.float32), multiples=[num_batch, 1])\n","                    # id = i * (grid_w + 1) + grid_w\n","                    tar = tf.concat([tf.slice(_theta, [0, i, j, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i, j + 1, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i + 1, j, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i + 1, j + 1, 0], [-1, 1, 1, -1])], axis=1)\n","\n","                    tar = tf.reshape(tar, [num_batch, 8])\n","\n","                    # tar = tf.Print(tar, [tf.slice(ori, [0, 0], [1, -1])],message=\"[ori--i:\"+str(i)+\",j:\"+str(j)+\"]:\",\n","                    # summarize=100,first_n=5)\n","                    # tar = tf.Print(tar, [tf.slice(tar, [0, 0], [1, -1])],message=\"[tar--i:\"+str(i)+\",j:\"+str(j)+\"]:\",\n","                    # summarize=100,first_n=5)\n","\n","                    hs.append(tf.reshape(tensorDLT_local.solve_DLT(ori, tar), [num_batch, 1, 9]))\n","\n","            hs = tf.reshape(tf.concat(hs, axis=1), [num_batch, grid_h, grid_w, 9], name='Hs')\n","        return hs\n","\n","    def _mesh_grid(height, width):\n","\n","        x_t = tf.matmul(tf.ones(shape=tf.stack([height, 1])),\n","                        tf.transpose(a=tf.expand_dims(tf.linspace(0., tf.cast(width, 'float32') - 1.001, width), 1),\n","                                     perm=[1, 0]))\n","        y_t = tf.matmul(tf.expand_dims(tf.linspace(0., tf.cast(height, 'float32') - 1.001, height), 1),\n","                        tf.ones(shape=tf.stack([1, width])))\n","\n","        x_t_flat = tf.reshape(x_t, (1, -1))\n","        y_t_flat = tf.reshape(y_t, (1, -1))\n","\n","        ones = tf.ones_like(x_t_flat)\n","        grid = tf.concat([x_t_flat, y_t_flat, ones], 0)\n","\n","        return grid\n","\n","    def _transform3(_theta, input_dim, _mask):\n","        with tf.compat.v1.variable_scope('_transform'):\n","            num_batch = tf.shape(input=input_dim)[0]\n","            height = tf.shape(input=input_dim)[1]\n","            width = tf.shape(input=input_dim)[2]\n","            num_channels = tf.shape(input=input_dim)[3]\n","\n","            # the width/height should be an integral multiple of grid_w/grid_h\n","            width_float = 512.\n","            height_float = 384.\n","\n","            _theta = tf.cast(_theta, 'float32')\n","            h_s = get_Hs(_theta, width_float, height_float)\n","\n","            ##########################################\n","            print(\"Hs\")\n","            print(h_s.shape)\n","            h_array = UpSampling2D(size=(384 / grid_h, 512 / grid_w))(h_s)\n","            h_array = tf.reshape(h_array, [-1, 3, 3])\n","            ##########################################\n","\n","            out_height = height\n","            out_width = width\n","            grid = _mesh_grid(out_height, out_width)\n","            grid = tf.expand_dims(grid, 0)\n","            grid = tf.reshape(grid, [-1])\n","            grid = tf.tile(grid, tf.stack([num_batch]))  # stack num_batch grids\n","            grid = tf.reshape(grid, tf.stack([num_batch, 3, -1]))\n","            print(\"grid\")\n","            print(grid.shape)\n","            # [bs, 3, N]\n","\n","            grid = tf.expand_dims(tf.transpose(a=grid, perm=[0, 2, 1]), 3)\n","            # [bs, 3, N] -> [bs, N, 3] -> [bs, N, 3, 1]\n","            grid = tf.reshape(grid, [-1, 3, 1])\n","            # [bs*N, 3, 1]\n","\n","            grid_row = tf.reshape(grid, [-1, 3])\n","            print(\"grid_row\")\n","            print(grid_row.shape)\n","            x_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 0, :], grid_row), axis=1)\n","            y_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 1, :], grid_row), axis=1)\n","            t_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 2, :], grid_row), axis=1)\n","\n","            # The problem may be here as a general homo does not preserve the parallelism\n","            # while an affine transformation preserves it.\n","            t_s_flat = tf.reshape(t_s, [-1])\n","            t_1 = tf.ones(shape=tf.shape(input=t_s_flat))\n","            t_0 = tf.zeros(shape=tf.shape(input=t_s_flat))\n","            sign_t = tf.compat.v1.where(t_s_flat >= 0, t_1, t_0) * 2 - 1\n","            t_s_flat = t_s_flat + sign_t * 1e-8\n","\n","            x_s_flat = tf.reshape(x_s, [-1]) / t_s_flat\n","            y_s_flat = tf.reshape(y_s, [-1]) / t_s_flat\n","\n","            out_size = (height, width)\n","            input_transformed = _interpolate(input_dim, x_s_flat, y_s_flat, out_size)\n","            mask_transformed = _interpolate(_mask, x_s_flat, y_s_flat, out_size)\n","\n","            _warp_image = tf.reshape(input_transformed, tf.stack([num_batch, height, width, num_channels]),\n","                                     name='output_img')\n","            _warp_mask = tf.reshape(mask_transformed, tf.stack([num_batch, height, width, num_channels]),\n","                                    name='output_mask')\n","\n","            return _warp_image, _warp_mask\n","\n","    with tf.compat.v1.variable_scope(name):\n","        # output = _transform(theta, U, out_size)\n","        _u = _u - 1.\n","        warp_image, warp_mask = _transform3(theta, _u, mask)\n","        warp_image = warp_image + 1.\n","        warp_image = tf.clip_by_value(warp_image, -1, 1)\n","        return warp_image, warp_mask"],"metadata":{"id":"ME3pPRXQqDih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","import tensorflow as tf\n","from keras.layers import UpSampling2D\n","\n","\n","grid_w = GRID_W\n","grid_h = GRID_H\n","\n","\n","def transformer_feature(_u, theta, name='SpatialTransformer'):\n","    def _repeat_feature(x, n_repeats):\n","        with tf.compat.v1.variable_scope('_repeat'):\n","            rep = tf.transpose(\n","                a=tf.expand_dims(tf.ones(shape=tf.stack([n_repeats, ])), 1), perm=[1, 0])\n","            rep = tf.cast(rep, 'int32')\n","            x = tf.matmul(tf.reshape(x, (-1, 1)), rep)\n","            return tf.reshape(x, [-1])\n","\n","    def _interpolate_feature(im, x, y, out_size):\n","        with tf.compat.v1.variable_scope('_interpolate'):\n","            # constants\n","            num_batch = tf.shape(input=im)[0]\n","            height = tf.shape(input=im)[1]\n","            width = tf.shape(input=im)[2]\n","            channels = tf.shape(input=im)[3]\n","\n","            x = tf.cast(x, 'float32')\n","            y = tf.cast(y, 'float32')\n","\n","            out_height = out_size[0]\n","            out_width = out_size[1]\n","            zero = tf.zeros([], dtype='int32')\n","            max_y = tf.cast(tf.shape(input=im)[1] - 1, 'int32')\n","            max_x = tf.cast(tf.shape(input=im)[2] - 1, 'int32')\n","\n","            # scale indices from [-1, 1] to [0, width/height]\n","            # x = (x + 1.0)*(width_f) / 2.0\n","            # y = (y + 1.0)*(height_f) / 2.0\n","\n","            # do sampling\n","            x0 = tf.cast(tf.floor(x), 'int32')\n","            x1 = x0 + 1\n","            y0 = tf.cast(tf.floor(y), 'int32')\n","            y1 = y0 + 1\n","\n","            x0 = tf.clip_by_value(x0, zero, max_x)\n","            x1 = tf.clip_by_value(x1, zero, max_x)\n","            y0 = tf.clip_by_value(y0, zero, max_y)\n","            y1 = tf.clip_by_value(y1, zero, max_y)\n","            dim2 = width\n","            dim1 = width * height\n","            base = _repeat_feature(tf.range(num_batch) * dim1, out_height * out_width)\n","            base_y0 = base + y0 * dim2\n","            base_y1 = base + y1 * dim2\n","            idx_a = base_y0 + x0\n","            idx_b = base_y1 + x0\n","            idx_c = base_y0 + x1\n","            idx_d = base_y1 + x1\n","\n","            # use indices to lookup pixels in the flat image and restore\n","            # channels dim\n","            im_flat = tf.reshape(im, tf.stack([-1, channels]))\n","            im_flat = tf.cast(im_flat, 'float32')\n","            ia = tf.gather(im_flat, idx_a)\n","            ib = tf.gather(im_flat, idx_b)\n","            ic = tf.gather(im_flat, idx_c)\n","            i_d = tf.gather(im_flat, idx_d)\n","\n","            # and finally calculate interpolated values\n","            x0_f = tf.cast(x0, 'float32')\n","            x1_f = tf.cast(x1, 'float32')\n","            y0_f = tf.cast(y0, 'float32')\n","            y1_f = tf.cast(y1, 'float32')\n","            wa = tf.expand_dims(((x1_f - x) * (y1_f - y)), 1)\n","            wb = tf.expand_dims(((x1_f - x) * (y - y0_f)), 1)\n","            wc = tf.expand_dims(((x - x0_f) * (y1_f - y)), 1)\n","            wd = tf.expand_dims(((x - x0_f) * (y - y0_f)), 1)\n","            output = tf.add_n([wa * ia, wb * ib, wc * ic, wd * i_d])\n","            return output\n","\n","    # input:  batch_size*(grid_h+1)*(grid_w+1)*2\n","    # output: batch_size*grid_h*grid_w*9\n","    def get_Hs_feature(_theta, width, height):\n","        with tf.compat.v1.variable_scope('get_Hs'):\n","            num_batch = tf.shape(input=_theta)[0]\n","            h = height / grid_h\n","            w = width / grid_w\n","            hs = []\n","            for i in range(grid_h):\n","                for j in range(grid_w):\n","                    hh = i * h\n","                    ww = j * w\n","                    ori = tf.tile(\n","                        tf.constant([ww, hh, ww + w, hh, ww, hh + h, ww + w, hh + h], shape=[1, 8], dtype=tf.float32),\n","                        multiples=[num_batch, 1])\n","                    # id = i * (grid_w + 1) + grid_w\n","                    tar = tf.concat([tf.slice(_theta, [0, i, j, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i, j + 1, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i + 1, j, 0], [-1, 1, 1, -1]),\n","                                     tf.slice(_theta, [0, i + 1, j + 1, 0], [-1, 1, 1, -1])], axis=1)\n","\n","                    tar = tf.reshape(tar, [num_batch, 8])\n","\n","                    hs.append(tf.reshape(tensorDLT_local.solve_DLT(ori, tar), [num_batch, 1, 9]))\n","            hs = tf.reshape(tf.concat(hs, axis=1), [num_batch, grid_h, grid_w, 9], name='Hs')\n","        return hs\n","\n","    def _mesh_grid_feature(height, width):\n","        x_t = tf.matmul(tf.ones(shape=tf.stack([height, 1])),\n","                        tf.transpose(a=tf.expand_dims(tf.linspace(0., tf.cast(width, 'float32') - 1.001, width), 1),\n","                                     perm=[1, 0]))\n","        y_t = tf.matmul(tf.expand_dims(tf.linspace(0., tf.cast(height, 'float32') - 1.001, height), 1),\n","                        tf.ones(shape=tf.stack([1, width])))\n","\n","        x_t_flat = tf.reshape(x_t, (1, -1))\n","        y_t_flat = tf.reshape(y_t, (1, -1))\n","\n","        ones = tf.ones_like(x_t_flat)\n","        grid = tf.concat([x_t_flat, y_t_flat, ones], 0)\n","\n","        return grid\n","\n","    def _transform3_feature(_theta, input_dim):\n","        with tf.compat.v1.variable_scope('_transform'):\n","            num_batch = tf.shape(input=input_dim)[0]\n","            height = tf.shape(input=input_dim)[1]\n","            width = tf.shape(input=input_dim)[2]\n","            num_channels = tf.shape(input=input_dim)[3]\n","\n","            # the width/height should be an integral multiple of grid_w/grid_h\n","            width_float = 32.\n","            height_float = 24.\n","\n","            _theta = tf.cast(_theta, 'float32')\n","            hs = get_Hs_feature(_theta, width_float, height_float)\n","\n","            ##########################################\n","            print(\"Hs\")\n","            print(hs.shape)\n","            h_array = UpSampling2D(size=(24 / grid_h, 32 / grid_w))(hs)\n","            h_array = tf.reshape(h_array, [-1, 3, 3])\n","            ##########################################\n","\n","            out_height = height\n","            out_width = width\n","            grid = _mesh_grid_feature(out_height, out_width)\n","            grid = tf.expand_dims(grid, 0)\n","            grid = tf.reshape(grid, [-1])\n","            grid = tf.tile(grid, tf.stack([num_batch]))  # stack num_batch grids\n","            grid = tf.reshape(grid, tf.stack([num_batch, 3, -1]))\n","            print(\"grid\")\n","            print(grid.shape)\n","            # [bs, 3, N]\n","\n","            grid = tf.expand_dims(tf.transpose(a=grid, perm=[0, 2, 1]), 3)\n","            # [bs, 3, N] -> [bs, N, 3] -> [bs, N, 3, 1]\n","            grid = tf.reshape(grid, [-1, 3, 1])\n","            # [bs*N, 3, 1]\n","\n","            grid_row = tf.reshape(grid, [-1, 3])\n","            print(\"grid_row\")\n","            print(grid_row.shape)\n","            x_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 0, :], grid_row), axis=1)\n","            y_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 1, :], grid_row), axis=1)\n","            t_s = tf.reduce_sum(input_tensor=tf.multiply(h_array[:, 2, :], grid_row), axis=1)\n","\n","            # The problem may be here as a general homo does not preserve the parallelism\n","            # while an affine transformation preserves it.\n","            t_s_flat = tf.reshape(t_s, [-1])\n","            t_1 = tf.ones(shape=tf.shape(input=t_s_flat))\n","            t_0 = tf.zeros(shape=tf.shape(input=t_s_flat))\n","            sign_t = tf.compat.v1.where(t_s_flat >= 0, t_1, t_0) * 2 - 1\n","            t_s_flat = t_s_flat + sign_t * 1e-8\n","\n","            x_s_flat = tf.reshape(x_s, [-1]) / t_s_flat\n","            y_s_flat = tf.reshape(y_s, [-1]) / t_s_flat\n","\n","            out_size = (height, width)\n","            input_transformed = _interpolate_feature(input_dim, x_s_flat, y_s_flat, out_size)\n","            # mask_transformed = _interpolate(mask, x_s_flat, y_s_flat, out_size)\n","\n","            _warp_image = tf.reshape(input_transformed, tf.stack([num_batch, height, width, num_channels]),\n","                                     name='output_img')\n","\n","            return _warp_image\n","\n","    with tf.compat.v1.variable_scope(name):\n","        # output = _transform(theta, U, out_size)\n","        # U = U - 1.\n","        warp_image = _transform3_feature(theta, _u)\n","        # warp_image = warp_image + 1.\n","        # warp_image = tf.clip_by_value(warp_image, -1, 1)\n","        return warp_image"],"metadata":{"id":"EI8tte-tqfaT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","grid_w = GRID_W\n","grid_h = GRID_H\n","\n","min_w = (512 / grid_w) / 8\n","min_h = (384 / grid_h) / 8\n","\n","\n","# pixel-level loss (l_num=1 for L1 loss, l_num=2 for L2 loss, ......)\n","def intensity_loss(gen_frames, gt_frames, l_num):\n","    return tf.reduce_mean(input_tensor=tf.abs((gen_frames - gt_frames) ** l_num))\n","\n","\n","# intra-grid constraint\n","def intra_grid_loss(pts):\n","    with tf.compat.v1.name_scope('soft_mesh_loss2'):\n","\n","        delta_x = pts[:, :, 0:grid_w, 0] - pts[:, :, 1:grid_w + 1, 0]\n","        delta_y = pts[:, 0:grid_h, :, 1] - pts[:, 1:grid_h + 1, :, 1]\n","\n","        loss_x = tf.nn.relu(delta_x + min_w)\n","        loss_y = tf.nn.relu(delta_y + min_h)\n","\n","        loss = tf.reduce_mean(input_tensor=loss_x) + tf.reduce_mean(input_tensor=loss_y)\n","\n","    return loss\n","\n","\n","# inter-grid constraint\n","def inter_grid_loss(train_mesh):\n","    w_edges = train_mesh[:, :, 0:grid_w, :] - train_mesh[:, :, 1:grid_w + 1, :]\n","    cos_w = tf.reduce_sum(input_tensor=w_edges[:, :, 0:grid_w - 1, :] * w_edges[:, :, 1:grid_w, :], axis=3) / (\n","                tf.sqrt(tf.reduce_sum(input_tensor=w_edges[:, :, 0:grid_w - 1, :] * w_edges[:, :, 0:grid_w - 1, :], axis=3)) * tf.sqrt(\n","                    tf.reduce_sum(input_tensor=w_edges[:, :, 1:grid_w, :] * w_edges[:, :, 1:grid_w, :], axis=3)))\n","    print(\"cos_w.shape\")\n","    print(cos_w.shape)\n","    delta_w_angle = 1 - cos_w\n","\n","    h_edges = train_mesh[:, 0:grid_h, :, :] - train_mesh[:, 1:grid_h + 1, :, :]\n","    cos_h = tf.reduce_sum(input_tensor=h_edges[:, 0:grid_h - 1, :, :] * h_edges[:, 1:grid_h, :, :], axis=3) / (\n","                tf.sqrt(tf.reduce_sum(input_tensor=h_edges[:, 0:grid_h - 1, :, :] * h_edges[:, 0:grid_h - 1, :, :], axis=3)) * tf.sqrt(\n","                    tf.reduce_sum(input_tensor=h_edges[:, 1:grid_h, :, :] * h_edges[:, 1:grid_h, :, :], axis=3)))\n","\n","    delta_h_angle = 1 - cos_h\n","\n","    loss = tf.reduce_mean(input_tensor=delta_w_angle) + tf.reduce_mean(input_tensor=delta_h_angle)\n","\n","    return loss"],"metadata":{"id":"SFxck1lSqnkf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import tf_slim as slim\n","\n","\n","grid_w = GRID_W\n","grid_h = GRID_H\n","\n","\n","def shift2mesh(mesh_shift, width, height):\n","    batch_size = tf.shape(input=mesh_shift)[0]\n","    h = height / grid_h\n","    w = width / grid_w\n","    ori_pt = []\n","    for i in range(grid_h + 1):\n","        for j in range(grid_w + 1):\n","            ww = j * w\n","            hh = i * h\n","            p = tf.constant([ww, hh], shape=[2], dtype=tf.float32)\n","            ori_pt.append(tf.expand_dims(p, 0))\n","    ori_pt = tf.concat(ori_pt, axis=0)\n","    ori_pt = tf.reshape(ori_pt, [grid_h + 1, grid_w + 1, 2])\n","    ori_pt = tf.tile(tf.expand_dims(ori_pt, 0), [batch_size, 1, 1, 1])\n","\n","    tar_pt = ori_pt + mesh_shift\n","    # tar_pt = tf.reshape(tar_pt, [batch_size, grid_h+1, grid_w+1, 2])\n","\n","    return tar_pt\n","\n","\n","def RectanglingNetwork(train_input, train_mask, width=512., height=384.):\n","    mesh_shift_primary, mesh_shift_final = build_model(train_input, train_mask)\n","\n","    mesh_primary = shift2mesh(mesh_shift_primary, width, height)\n","    mesh_final = shift2mesh(mesh_shift_final + mesh_shift_primary, width, height)\n","\n","    warp_image_primary, warp_mask_primary = tf_spatial_transform_local.transformer(train_input, train_mask,\n","                                                                                   mesh_primary)\n","    warp_image_final, warp_mask_final = tf_spatial_transform_local.transformer(train_input, train_mask, mesh_final)\n","\n","    return mesh_primary, warp_image_primary, warp_mask_primary, mesh_final, warp_image_final, warp_mask_final\n","\n","\n","# feature extraction module\n","def feature_extractor(image_tf):\n","    feature = []\n","    # 512*384\n","    with tf.compat.v1.variable_scope('conv_block1'):\n","        conv1 = tf.compat.v1.layers.conv2d(inputs=image_tf, num_outputs=64, kernel_size=3, rate=1, activation_fn=tf.nn.relu)\n","        conv1 = tf.compat.v1.layers.conv2d(inputs=conv1, num_outputs=64, kernel_size=3, rate=1, activation_fn=tf.nn.relu)\n","        maxpool1 = slim.max_pool2d(conv1, 2, stride=2, padding='SAME')\n","    # 256*192\n","    with tf.compat.v1.variable_scope('conv_block2'):\n","        conv2 = tf.compat.v1.layers.conv2d(inputs=maxpool1, num_outputs=64, kernel_size=3, activation_fn=tf.nn.relu)\n","        conv2 = tf.compat.v1.layers.conv2d(inputs=conv2, num_outputs=64, kernel_size=3, activation_fn=tf.nn.relu)\n","        maxpool2 = slim.max_pool2d(conv2, 2, stride=2, padding='SAME')\n","    # 128*96\n","    with tf.compat.v1.variable_scope('conv_block3'):\n","        conv3 = tf.compat.v1.layers.conv2d(inputs=maxpool2, num_outputs=128, kernel_size=3, activation_fn=tf.nn.relu)\n","        conv3 = tf.compat.v1.layers.conv2d(inputs=conv3, num_outputs=128, kernel_size=3, activation_fn=tf.nn.relu)\n","        maxpool3 = slim.max_pool2d(conv3, 2, stride=2, padding='SAME')\n","    # 64*48\n","    with tf.compat.v1.variable_scope('conv_block4'):\n","        conv4 = tf.compat.v1.layers.conv2d(inputs=maxpool3, num_outputs=128, kernel_size=3, activation_fn=tf.nn.relu)\n","        conv4 = tf.compat.v1.layers.conv2d(inputs=conv4, num_outputs=128, kernel_size=3, activation_fn=tf.nn.relu)\n","        feature.append(conv4)\n","\n","    return feature\n","\n","\n","# mesh motion regression module\n","def regression_Net(correlation):\n","    conv1 = tf.compat.v1.layers.conv2d(inputs=correlation, num_outputs=256, kernel_size=3, activation_fn=tf.nn.relu)\n","    conv1 = tf.compat.v1.layers.conv2d(inputs=conv1, num_outputs=256, kernel_size=3, activation_fn=tf.nn.relu)\n","\n","    maxpool1 = slim.max_pool2d(conv1, 2, stride=2, padding='SAME')  # 16\n","    conv2 = tf.compat.v1.layers.conv2d(inputs=maxpool1, num_outputs=256, kernel_size=3, activation_fn=tf.nn.relu)\n","    conv2 = tf.compat.v1.layers.conv2d(inputs=conv2, num_outputs=256, kernel_size=3, activation_fn=tf.nn.relu)\n","\n","    maxpool2 = slim.max_pool2d(conv2, 2, stride=2, padding='SAME')  # 8\n","    conv3 = tf.compat.v1.layers.conv2d(inputs=maxpool2, num_outputs=512, kernel_size=3, activation_fn=tf.nn.relu)\n","    conv3 = tf.compat.v1.layers.conv2d(inputs=conv3, num_outputs=512, kernel_size=3, activation_fn=tf.nn.relu)\n","\n","    maxpool3 = slim.max_pool2d(conv3, 2, stride=2, padding='SAME')  # 4\n","    conv4 = tf.compat.v1.layers.conv2d(inputs=maxpool3, num_outputs=512, kernel_size=3, activation_fn=tf.nn.relu)\n","    conv4 = tf.compat.v1.layers.conv2d(inputs=conv4, num_outputs=512, kernel_size=3, activation_fn=tf.nn.relu)\n","\n","    fc1 = tf.compat.v1.layers.conv2d(inputs=conv4, num_outputs=2048, kernel_size=[3, 4], activation_fn=tf.nn.relu, padding=\"VALID\")\n","    fc2 = tf.compat.v1.layers.conv2d(inputs=fc1, num_outputs=1024, kernel_size=1, activation_fn=tf.nn.relu)\n","    fc3 = tf.compat.v1.layers.conv2d(inputs=fc2, num_outputs=(grid_w + 1) * (grid_h + 1) * 2, kernel_size=1, activation_fn=None)\n","    # net3_f = tf.expand_dims(tf.squeeze(tf.squeeze(fc3,1),1), [2])\n","    net3_f_local = tf.reshape(fc3, (-1, grid_h + 1, grid_w + 1, 2))\n","\n","    return net3_f_local\n","\n","\n","def build_model(train_input, train_mask):\n","    with tf.compat.v1.variable_scope('model'):\n","\n","        with tf.compat.v1.variable_scope('feature_extract', reuse=None):\n","            features = feature_extractor(tf.concat([train_input, train_mask], axis=3))\n","\n","        feature = tf.image.resize(features[-1], [24, 32], method=0)\n","        with tf.compat.v1.variable_scope('regression_coarse', reuse=None):\n","            mesh_shift_primary = regression_Net(feature)\n","\n","        with tf.compat.v1.variable_scope('regression_fine', reuse=None):\n","            mesh_primary = shift2mesh(mesh_shift_primary / 16, 32., 24.)\n","            feature_warp = tf_spatial_transform_local_feature.transformer_feature(feature, mesh_primary)\n","            mesh_shift_final = regression_Net(feature_warp)\n","\n","        return mesh_shift_primary, mesh_shift_final"],"metadata":{"id":"DbsDzUkxqv5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from collections import OrderedDict\n","import sys\n","import os\n","import glob\n","import cv2\n","\n","rng = np.random.RandomState(2017)\n","\n","\n","class DataLoader(object):\n","    def __init__(self, data_folder):\n","        self.dir = data_folder\n","        self.datas = OrderedDict()\n","        self.setup()\n","\n","    def __call__(self, batch_size):\n","        data_info_list = list(self.datas.values())\n","        length = data_info_list[0]['length']\n","\n","        def data_clip_generator():\n","            while True:\n","                data_clip = []\n","                frame_id = rng.randint(0, length - 1)\n","                # inputs\n","\n","                input_img = np_load_frame(data_info_list[1]['frame'][frame_id], 384, 512)\n","                mask_img = np_load_frame(data_info_list[2]['frame'][frame_id], 384, 512)\n","                gt_img = np_load_frame(data_info_list[0]['frame'][frame_id], 384, 512)\n","\n","                data_clip.append(input_img)\n","                data_clip.append(mask_img)\n","                data_clip.append(gt_img)\n","                data_clip = np.concatenate(data_clip, axis=2)\n","\n","                yield data_clip\n","\n","                # creating augmentations\n","\n","                data_clip = []\n","\n","                flipped_input = np.fliplr(input_img)\n","                flipped_mask = np.fliplr(mask_img)\n","                flipped_gt = np.fliplr(gt_img)\n","\n","                data_clip.append(flipped_input)\n","                data_clip.append(flipped_mask)\n","                data_clip.append(flipped_gt)\n","                data_clip = np.concatenate(data_clip, axis=2)\n","\n","                yield data_clip\n","\n","        dataset = tf.data.Dataset.from_generator(generator=data_clip_generator, output_types=tf.float32,\n","                                                 output_shapes=[384, 512, 9])\n","\n","        print('generator dataset, {}'.format(dataset))\n","        dataset = dataset.prefetch(buffer_size=128)\n","        dataset = dataset.shuffle(buffer_size=128).batch(batch_size)\n","        print('epoch dataset, {}'.format(dataset))\n","\n","        return dataset\n","\n","    def __getitem__(self, data_name):\n","        assert data_name in self.datas.keys(), 'data = {} is not in {}!'.format(data_name, self.datas.keys())\n","        return self.datas[data_name]\n","\n","    def setup(self):\n","        datas = glob.glob(os.path.join(self.dir, '*'))\n","        for data in sorted(datas):\n","\n","            if sys.platform[:3] == 'win':\n","                data_name = data.split('\\\\')[-1]\n","            else:\n","                data_name = data.split('/')[-1]\n","\n","            if data_name == 'gt' or data_name == 'input' or data_name == 'mask':\n","                self.datas[data_name] = {}\n","                self.datas[data_name]['path'] = data\n","                self.datas[data_name]['frame'] = glob.glob(os.path.join(data, '*.jpg'))\n","                self.datas[data_name]['frame'].sort()\n","                self.datas[data_name]['length'] = len(self.datas[data_name]['frame'])\n","\n","        print(self.datas.keys())\n","\n","    def get_data_clips(self, index):\n","        batch = []\n","        data_info_list = list(self.datas.values())\n","\n","        batch.append(np_load_frame(data_info_list[1]['frame'][index], 384, 512))\n","        batch.append(np_load_frame(data_info_list[2]['frame'][index], 384, 512))\n","        batch.append(np_load_frame(data_info_list[0]['frame'][index], 384, 512))\n","\n","        return np.concatenate(batch, axis=2)\n","\n","\n","def np_load_frame(filename, resize_height, resize_width):\n","    image_decoded = cv2.imread(filename)\n","\n","    if resize_height is not None:\n","        image_resized = cv2.resize(image_decoded, (resize_width, resize_height))\n","    else:\n","        image_resized = image_decoded\n","\n","    image_resized = image_resized.astype(dtype=np.float32)\n","    image_resized = (image_resized / 127.5) - 1.0\n","    return image_resized\n","\n","\n","def load(saver, sess, ckpt_path):\n","    print(ckpt_path)\n","    saver.restore(sess, ckpt_path)\n","    print(\"Restored model parameters from {}\".format(ckpt_path))\n","\n","\n","def save(saver, sess, logdir, step):\n","    model_name = 'model.ckpt'\n","    checkpoint_path = os.path.join(logdir, model_name)\n","    if not os.path.exists(logdir):\n","        os.makedirs(logdir)\n","    saver.save(sess, checkpoint_path, global_step=step, save_format='h5')\n","    print('The checkpoint has been created.')"],"metadata":{"id":"U-xFtQunq9hF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import os\n","import numpy as np\n","import cv2 as cv\n","\n","os.environ['CUDA_DEVICES_ORDER'] = \"PCI_BUS_ID\"\n","os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n","\n","test_folder = TEST_FOLDER\n","batch_size = TEST_BATCH_SIZE\n","grid_w = GRID_W\n","grid_h = GRID_H\n","\n","\n","def draw_mesh_on_warp(warp, f_local):\n","    min_w = np.minimum(np.min(f_local[:, :, 0]), 0).astype(np.int32)\n","    max_w = np.maximum(np.max(f_local[:, :, 0]), 512).astype(np.int32)\n","    min_h = np.minimum(np.min(f_local[:, :, 1]), 0).astype(np.int32)\n","    max_h = np.maximum(np.max(f_local[:, :, 1]), 384).astype(np.int32)\n","    cw = max_w - min_w\n","    ch = max_h - min_h\n","\n","    pic = np.ones([ch + 10, cw + 10, 3], np.int32) * 255\n","    pic[0 - min_h + 5:0 - min_h + 384 + 5, 0 - min_w + 5:0 - min_w + 512 + 5, :] = warp\n","\n","    warp = pic\n","    f_local[:, :, 0] = f_local[:, :, 0] - min_w + 5\n","    f_local[:, :, 1] = f_local[:, :, 1] - min_h + 5\n","\n","    point_color = (0, 255, 0)  # BGR\n","    thickness = 2\n","    line_type = 8\n","    num = 1\n","\n","    for i in range(grid_h + 1):\n","        for j in range(grid_w + 1):\n","            num = num + 1\n","            if j == grid_w and i == grid_h:\n","                continue\n","            elif j == grid_w:\n","                cv.line(warp, (f_local[i, j, 0], f_local[i, j, 1]), (f_local[i + 1, j, 0], f_local[i + 1, j, 1]),\n","                        point_color, thickness, line_type)\n","            elif i == grid_h:\n","                cv.line(warp, (f_local[i, j, 0], f_local[i, j, 1]), (f_local[i, j + 1, 0], f_local[i, j + 1, 1]),\n","                        point_color, thickness, line_type)\n","            else:\n","                cv.line(warp, (f_local[i, j, 0], f_local[i, j, 1]), (f_local[i + 1, j, 0], f_local[i + 1, j, 1]),\n","                        point_color, thickness, line_type)\n","                cv.line(warp, (f_local[i, j, 0], f_local[i, j, 1]), (f_local[i, j + 1, 0], f_local[i, j + 1, 1]),\n","                        point_color, thickness, line_type)\n","\n","    return warp\n","\n","\n","snapshot_dir = '/content/drive/MyDrive/Colab Notebooks/checkpoints/pretrained_model/model.ckpt-100000'\n","\n","# define dataset\n","with tf.compat.v1.name_scope('dataset'):\n","    # ----------- testing ----------- #\n","    tf.compat.v1.disable_eager_execution()\n","    test_inputs_clips_tensor = tf.compat.v1.placeholder(shape=[batch_size, None, None, 3 * 3], dtype=tf.float32)\n","\n","    test_input = test_inputs_clips_tensor[..., 0:3]\n","    test_mask = test_inputs_clips_tensor[..., 3:6]\n","    test_gt = test_inputs_clips_tensor[..., 6:9]\n","\n","    print('test input = {}'.format(test_input))\n","    print('test mask = {}'.format(test_mask))\n","    print('test gt = {}'.format(test_gt))\n","\n","# define testing generator function\n","with tf.compat.v1.variable_scope('generator', reuse=None):\n","    print('testing = {}'.format(tf.compat.v1.get_variable_scope().name))\n","    test_mesh_primary, test_warp_image_primary, test_warp_mask_primary, test_mesh_final, test_warp_image_final, \\\n","        test_warp_mask_final = RectanglingNetwork(test_input, test_mask)\n","\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","with tf.compat.v1.Session(config=config) as sess:\n","    # dataset\n","    input_loader = DataLoader(test_folder)\n","\n","    # initialize weights\n","    sess.run(tf.compat.v1.global_variables_initializer())\n","    print('Init global successfully!')\n","\n","    # tf saver\n","    saver = tf.compat.v1.train.Saver(var_list=tf.compat.v1.global_variables(), max_to_keep=None)\n","\n","    restore_var = [v for v in tf.compat.v1.global_variables()]\n","    loader = tf.compat.v1.train.Saver(var_list=restore_var)\n","\n","\n","    def inference_func(ckpt):\n","        print(\"============\")\n","        print(ckpt)\n","        load(loader, sess, ckpt)\n","        print(\"============\")\n","        length = 519  # len(os.listdir(test_folder+\"/input\"))\n","\n","        for i in range(0, length):\n","            input_clip = np.expand_dims(input_loader.get_data_clips(i), axis=0)\n","\n","            mesh_primary, warp_image_primary, warp_mask_primary, mesh_final, warp_image_final, warp_mask_final = \\\n","                sess.run([test_mesh_primary, test_warp_image_primary, test_warp_mask_primary, test_mesh_final,\n","                          test_warp_image_final, test_warp_mask_final],\n","                         feed_dict={test_inputs_clips_tensor: input_clip})\n","\n","            mesh = mesh_final[0]\n","            input_image = (input_clip[0, :, :, 0:3] + 1) / 2 * 255\n","\n","            input_image = draw_mesh_on_warp(input_image, mesh)\n","            # input_mask = draw_mesh_on_warp(np.ones([384, 512, 3], np.int32)*255, mesh)\n","\n","            path = \"../final_mesh/\" + str(i + 1).zfill(5) + \".jpg\"\n","            cv.imwrite(path, input_image)\n","\n","            # path = \"../mesh_mask/\" + str(i+1).zfill(5) + \".jpg\"\n","            # cv.imwrite(path, input_mask)\n","\n","            print('i = {} / {}'.format(i + 1, length))\n","\n","\n","    inference_func(snapshot_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"g0oVgzWArD22","executionInfo":{"status":"error","timestamp":1660670606511,"user_tz":-180,"elapsed":621,"user":{"displayName":"Kareem Mokhtar","userId":"13629540510544543980"}},"outputId":"45c282f4-ce57-4664-dbfd-557b86c44f3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test input = Tensor(\"strided_slice:0\", shape=(1, None, None, 3), dtype=float32)\n","test mask = Tensor(\"strided_slice_1:0\", shape=(1, None, None, 3), dtype=float32)\n","test gt = Tensor(\"strided_slice_2:0\", shape=(1, None, None, 3), dtype=float32)\n","testing = generator\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-c484a8fb5a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testing = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtest_mesh_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_warp_image_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_warp_mask_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mesh_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_warp_image_final\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mtest_warp_mask_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRectanglingNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-51e03db5e89f>\u001b[0m in \u001b[0;36mRectanglingNetwork\u001b[0;34m(train_input, train_mask, width, height)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mRectanglingNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m384.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmesh_shift_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh_shift_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmesh_primary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift2mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_shift_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-51e03db5e89f>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(train_input, train_mask)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_extract'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-51e03db5e89f>\u001b[0m in \u001b[0;36mfeature_extractor\u001b[0;34m(image_tf)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# 512*384\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv_block1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mmaxpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: conv2d() got an unexpected keyword argument 'num_outputs'"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import os\n","import numpy as np\n","import scipy.io\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","os.environ['CUDA_DEVICES_ORDER'] = \"PCI_BUS_ID\"\n","os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n","\n","train_folder = TRAIN_FOLDER\n","test_folder = TEST_FOLDER\n","\n","batch_size = TRAIN_BATCH_SIZE\n","iterations = ITERATIONS\n","\n","height, width = 384, 512\n","\n","summary_dir = SUMMARY_DIR\n","snapshot_dir = SNAPSHOT_DIR\n","\n","\n","def build_net(ntype, nin, nwb=None, name=None):\n","    if ntype == 'conv':\n","        return tf.nn.relu(tf.nn.conv2d(input=nin, filters=nwb[0], strides=[1, 1, 1, 1], padding='SAME', name=name) + nwb[1])\n","    elif ntype == 'pool':\n","        return tf.nn.avg_pool2d(input=nin, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n","\n","\n","def get_weight_bias(vgg_layers, _i):\n","    weights = vgg_layers[_i][0][0][2][0][0]\n","    weights = tf.constant(weights)\n","    bias = vgg_layers[_i][0][0][2][0][1]\n","    bias = tf.constant(np.reshape(bias, bias.size))\n","    return weights, bias\n","\n","\n","vgg_path = scipy.io.loadmat('./vgg19/imagenet-vgg-verydeep-19.mat')\n","print(\"[i] Loaded pre-trained vgg19 parameters\")\n","\n","\n","# build VGG19 to load pre-trained parameters\n","def build_vgg19(_input, reuse=False):\n","    with tf.compat.v1.variable_scope(\"vgg19\"):\n","        if reuse:\n","            tf.compat.v1.get_variable_scope().reuse_variables()\n","        net = {}\n","        vgg_layers = vgg_path['layers'][0]\n","        net['input'] = _input - np.array([123.6800, 116.7790, 103.9390]).reshape((1, 1, 1, 3))\n","        net['conv1_1'] = build_net('conv', net['input'], get_weight_bias(vgg_layers, 0), name='vgg_conv1_1')\n","        net['conv1_2'] = build_net('conv', net['conv1_1'], get_weight_bias(vgg_layers, 2), name='vgg_conv1_2')\n","        net['pool1'] = build_net('pool', net['conv1_2'])\n","        net['conv2_1'] = build_net('conv', net['pool1'], get_weight_bias(vgg_layers, 5), name='vgg_conv2_1')\n","        net['conv2_2'] = build_net('conv', net['conv2_1'], get_weight_bias(vgg_layers, 7), name='vgg_conv2_2')\n","        net['pool2'] = build_net('pool', net['conv2_2'])\n","        net['conv3_1'] = build_net('conv', net['pool2'], get_weight_bias(vgg_layers, 10), name='vgg_conv3_1')\n","        net['conv3_2'] = build_net('conv', net['conv3_1'], get_weight_bias(vgg_layers, 12), name='vgg_conv3_2')\n","        net['conv3_3'] = build_net('conv', net['conv3_2'], get_weight_bias(vgg_layers, 14), name='vgg_conv3_3')\n","        net['conv3_4'] = build_net('conv', net['conv3_3'], get_weight_bias(vgg_layers, 16), name='vgg_conv3_4')\n","        net['pool3'] = build_net('pool', net['conv3_4'])\n","        net['conv4_1'] = build_net('conv', net['pool3'], get_weight_bias(vgg_layers, 19), name='vgg_conv4_1')\n","        net['conv4_2'] = build_net('conv', net['conv4_1'], get_weight_bias(vgg_layers, 21), name='vgg_conv4_2')\n","        net['conv4_3'] = build_net('conv', net['conv4_2'], get_weight_bias(vgg_layers, 23), name='vgg_conv4_3')\n","        net['conv4_4'] = build_net('conv', net['conv4_3'], get_weight_bias(vgg_layers, 25), name='vgg_conv4_4')\n","        net['pool4'] = build_net('pool', net['conv4_4'])\n","        net['conv5_1'] = build_net('conv', net['pool4'], get_weight_bias(vgg_layers, 28), name='vgg_conv5_1')\n","        net['conv5_2'] = build_net('conv', net['conv5_1'], get_weight_bias(vgg_layers, 30), name='vgg_conv5_2')\n","        print(type(net))\n","        return net\n","\n","\n","# define dataset\n","with tf.compat.v1.name_scope('dataset'):\n","    train_data_loader = DataLoader(train_folder)\n","    train_data_dataset = train_data_loader(batch_size=batch_size)\n","    train_data_it = tf.compat.v1.data.make_one_shot_iterator(train_data_dataset)\n","    train_input_tensor = train_data_it.get_next()\n","    train_input_tensor.set_shape([batch_size, height, width, 9])\n","\n","    train_input = train_input_tensor[:, :, :, 0:3]\n","    train_mask = train_input_tensor[:, :, :, 3:6]\n","    train_gt = train_input_tensor[:, :, :, 6:9]\n","\n","    print('train input = {}'.format(train_input))\n","    print('train mask = {}'.format(train_mask))\n","    print('train gt = {}'.format(train_gt))\n","\n","# define training rectangling function\n","with tf.compat.v1.variable_scope('generator', reuse=None):\n","    print('training = {}'.format(tf.compat.v1.get_variable_scope().name))\n","    train_mesh_primary, train_warp_image_primary, train_warp_mask_primary, train_mesh_final, train_warp_image_final, \\\n","        train_warp_mask_final = RectanglingNetwork(train_input, train_mask)\n","\n","# define appearance loss (loss 1 of of the content term)\n","lam_appearance = 1\n","if lam_appearance != 0:\n","    primary_appearance_loss = intensity_loss(gen_frames=train_warp_image_primary, gt_frames=train_gt, l_num=1)\n","    final_appearance_loss = intensity_loss(gen_frames=train_warp_image_final, gt_frames=train_gt, l_num=1)\n","    appearance_loss = primary_appearance_loss + final_appearance_loss\n","else:\n","    primary_appearance_loss = tf.constant(0.0, dtype=tf.float32)\n","    final_appearance_loss = tf.constant(0.0, dtype=tf.float32)\n","    appearance_loss = primary_appearance_loss + final_appearance_loss\n","\n","# define perception loss (loss 2 of of the content term)\n","primary_features_warp = build_vgg19((train_warp_image_primary + 1) * 127.5, reuse=False)\n","final_features_warp = build_vgg19((train_warp_image_final + 1) * 127.5, reuse=True)\n","features_gt = build_vgg19((train_gt + 1) * 127.5, reuse=True)\n","lam_perception = 5e-6\n","if lam_perception != 0:\n","    primary_perception_loss = intensity_loss(gen_frames=primary_features_warp['conv4_2'],\n","                                             gt_frames=features_gt['conv4_2'], l_num=2)\n","    final_perception_loss = intensity_loss(gen_frames=final_features_warp['conv4_2'], gt_frames=features_gt['conv4_2'],\n","                                           l_num=2)\n","    perception_loss = primary_perception_loss + final_perception_loss\n","else:\n","    primary_perception_loss = tf.constant(0.0, dtype=tf.float32)\n","    final_perception_loss = tf.constant(0.0, dtype=tf.float32)\n","    perception_loss = primary_perception_loss + final_perception_loss\n","\n","# define boundary term\n","lam_mask = 1\n","if lam_mask != 0:\n","    primary_mask_loss = intensity_loss(gen_frames=train_warp_mask_primary,\n","                                       gt_frames=tf.ones_like(train_warp_mask_primary), l_num=1)\n","    final_mask_loss = intensity_loss(gen_frames=train_warp_mask_final, gt_frames=tf.ones_like(train_warp_mask_final),\n","                                     l_num=1)\n","    mask_loss = primary_mask_loss + final_mask_loss\n","else:\n","    primary_mask_loss = tf.constant(0.0, dtype=tf.float32)\n","    final_mask_loss = tf.constant(0.0, dtype=tf.float32)\n","    mask_loss = primary_mask_loss + final_mask_loss\n","\n","# define mesh term\n","lam_mesh = 1\n","if lam_mesh != 0:\n","    primary_mesh_loss = intra_grid_loss(train_mesh_primary) + inter_grid_loss(train_mesh_primary)\n","    final_mesh_loss = intra_grid_loss(train_mesh_final) + inter_grid_loss(train_mesh_final)\n","    mesh_loss = primary_mesh_loss + final_mesh_loss\n","else:\n","    primary_mesh_loss = tf.constant(0.0, dtype=tf.float32)\n","    final_mesh_loss = tf.constant(0.0, dtype=tf.float32)\n","    mesh_loss = primary_mesh_loss + final_mesh_loss\n","\n","with tf.compat.v1.name_scope('training'):\n","    g_loss = tf.add_n([appearance_loss * lam_appearance, perception_loss * lam_perception, lam_mask * mask_loss,\n","                       mesh_loss * lam_mesh], name='g_loss')\n","\n","    g_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='g_step')\n","    g_lrate = tf.compat.v1.train.exponential_decay(0.0001, g_step, decay_steps=50000 / 4, decay_rate=0.96)\n","    g_optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=g_lrate, name='g_optimizer')\n","    g_vars = tf.compat.v1.get_collection(key=tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n","\n","    grads = g_optimizer.compute_gradients(g_loss, var_list=g_vars)\n","    for i, (g, v) in enumerate(grads):\n","        if g is not None:\n","            grads[i] = (tf.clip_by_norm(g, 3), v)  # clip gradients\n","    g_train_op = g_optimizer.apply_gradients(grads, global_step=g_step, name='g_train_op')\n","\n","# add all to summaries'\n","# loss\n","tf.compat.v1.summary.scalar(tensor=g_loss, name='g_loss')\n","tf.compat.v1.summary.scalar(tensor=appearance_loss, name='appearance_loss')\n","tf.compat.v1.summary.scalar(tensor=perception_loss, name='perception_loss')\n","tf.compat.v1.summary.scalar(tensor=mask_loss, name='mask_loss')\n","tf.compat.v1.summary.scalar(tensor=mesh_loss, name='mesh_loss')\n","# images\n","tf.compat.v1.summary.image(tensor=train_input, name='train_input')\n","tf.compat.v1.summary.image(tensor=train_mask, name='train_mask')\n","tf.compat.v1.summary.image(tensor=train_gt, name='train_gt')\n","tf.compat.v1.summary.image(tensor=train_warp_image_primary, name='train_warp_image_primary')\n","tf.compat.v1.summary.image(tensor=train_warp_image_final, name='train_warp_image_final')\n","\n","summary_op = tf.compat.v1.summary.merge_all()\n","\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","\n","with tf.compat.v1.Session(config=config) as sess:\n","    # summaries\n","    summary_writer = tf.compat.v1.summary.FileWriter(summary_dir, graph=sess.graph)\n","\n","    # initialize weights\n","    sess.run(tf.compat.v1.global_variables_initializer())\n","    print('Init successfully!')\n","\n","    # tf saver\n","    saver = tf.compat.v1.train.Saver(var_list=tf.compat.v1.global_variables(), max_to_keep=None)\n","    restore_var = [v for v in tf.compat.v1.global_variables()]\n","    loader = tf.compat.v1.train.Saver(var_list=restore_var)\n","    print(\"snapshot_dir\")\n","    print(snapshot_dir)\n","    if os.path.isdir(snapshot_dir):\n","        ckpt = tf.train.get_checkpoint_state(snapshot_dir)\n","        if ckpt and ckpt.model_checkpoint_path:\n","            load(loader, sess, ckpt.model_checkpoint_path)\n","        else:\n","            print('No checkpoint file found.')\n","    else:\n","        load(loader, sess, snapshot_dir)\n","\n","    _step, _loss, _summaries = 0, None, None\n","\n","    print(\"============starting training===========\")\n","    while _step < iterations:\n","        try:\n","            print('Training generator...')\n","            _, _g_lr, _step, _appearance_loss, _perception_loss, _mask_loss, _mesh_loss, _g_loss, _summaries = sess.run(\n","                [g_train_op, g_lrate, g_step, appearance_loss, perception_loss, mask_loss, mesh_loss, g_loss,\n","                 summary_op])\n","\n","            if _step % 100 == 0:\n","                print('GeneratorModel : Step {}, lr = {:.8f}'.format(_step, _g_lr))\n","                print('                 Global      Loss : ', _g_loss)\n","                print('                 appearance   Loss : ({:.4f} * {:.4f} = {:.4f})'.format(_appearance_loss,\n","                                                                                               lam_appearance,\n","                                                                                               _appearance_loss *\n","                                                                                               lam_appearance))\n","                print(\n","                    '                 vgg   Loss : ({:.4f} * {:.4f} = {:.4f})'.format(_perception_loss, lam_perception,\n","                                                                                      _perception_loss *\n","                                                                                      lam_perception))\n","                print('                 mask   Loss : ({:.4f} * {:.4f} = {:.4f})'.format(_mask_loss, lam_mask,\n","                                                                                         _mask_loss * lam_mask))\n","                print('                 mesh   Loss : ({:.4f} * {:.4f} = {:.4f})'.format(_mesh_loss, lam_mesh,\n","                                                                                         _mesh_loss * lam_mesh))\n","            if _step % 2000 == 0:\n","                summary_writer.add_summary(_summaries, global_step=_step)\n","                print('Save summaries...')\n","\n","            if _step == constant.ITERATIONS:\n","                save(saver, sess, snapshot_dir, _step)\n","\n","        except tf.errors.OutOfRangeError:\n","            print('Finish successfully!')\n","            save(saver, sess, snapshot_dir, _step)\n","            break"],"metadata":{"id":"Vl2r8zOKrF2Z"},"execution_count":null,"outputs":[]}]}